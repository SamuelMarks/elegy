
<!DOCTYPE html>

<html class="no-js" lang="en">
<head>
<meta charset="utf-8"/>
<meta content="width=device-width,initial-scale=1" name="viewport"/>
<link href="https://poets-ai.github.io/elegy/api/model/Model/" rel="canonical"/>
<link href="../../../images/favicon.png" rel="shortcut icon"/>
<meta content="mkdocs-1.1.2, mkdocs-material-5.5.0" name="generator"/>
<title>Model - Elegy</title>
<link href="../../../assets/stylesheets/main.b5d04df8.min.css" rel="stylesheet"/>
<link crossorigin="" href="https://fonts.gstatic.com" rel="preconnect"/>
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700%7CRoboto+Mono&amp;display=fallback" rel="stylesheet"/>
<style>body,input{font-family:"Roboto",-apple-system,BlinkMacSystemFont,Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono",SFMono-Regular,Consolas,Menlo,monospace}</style>
</head>
<body dir="ltr">
<input autocomplete="off" class="md-toggle" data-md-toggle="drawer" id="__drawer" type="checkbox"/>
<input autocomplete="off" class="md-toggle" data-md-toggle="search" id="__search" type="checkbox"/>
<label class="md-overlay" for="__drawer"></label>
<div data-md-component="skip">
<a class="md-skip" href="#elegymodel">
          Skip to content
        </a>
</div>
<div data-md-component="announce">
</div>
<header class="md-header" data-md-component="header">
<nav aria-label="Header" class="md-header-nav md-grid">
<a aria-label="Elegy" class="md-header-nav__button md-logo" href="https://poets-ai.github.io/elegy" title="Elegy">
<svg viewbox="0 0 640 512" xmlns="http://www.w3.org/2000/svg"><path d="M471.1 96C405 96 353.3 137.3 320 174.6 286.7 137.3 235 96 168.9 96 75.8 96 0 167.8 0 256s75.8 160 168.9 160c66.1 0 117.8-41.3 151.1-78.6 33.3 37.3 85 78.6 151.1 78.6 93.1 0 168.9-71.8 168.9-160S564.2 96 471.1 96zM168.9 320c-40.2 0-72.9-28.7-72.9-64s32.7-64 72.9-64c38.2 0 73.4 36.1 94 64-20.4 27.6-55.9 64-94 64zm302.2 0c-38.2 0-73.4-36.1-94-64 20.4-27.6 55.9-64 94-64 40.2 0 72.9 28.7 72.9 64s-32.7 64-72.9 64z"></path></svg>
</a>
<label class="md-header-nav__button md-icon" for="__drawer">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"></path></svg>
</label>
<div class="md-header-nav__title" data-md-component="header-title">
<div class="md-header-nav__ellipsis">
<span class="md-header-nav__topic md-ellipsis">
            Elegy
          </span>
<span class="md-header-nav__topic md-ellipsis">
            
              Model
            
          </span>
</div>
</div>
<label class="md-header-nav__button md-icon" for="__search">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M9.5 3A6.5 6.5 0 0116 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 019.5 16 6.5 6.5 0 013 9.5 6.5 6.5 0 019.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"></path></svg>
</label>
<div class="md-search" data-md-component="search" role="dialog">
<label class="md-search__overlay" for="__search"></label>
<div class="md-search__inner" role="search">
<form class="md-search__form" name="search">
<input aria-label="Search" autocapitalize="off" autocomplete="off" autocorrect="off" class="md-search__input" data-md-component="search-query" data-md-state="active" name="query" placeholder="Search" spellcheck="false" type="text"/>
<label class="md-search__icon md-icon" for="__search">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M9.5 3A6.5 6.5 0 0116 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 019.5 16 6.5 6.5 0 013 9.5 6.5 6.5 0 019.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"></path></svg>
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"></path></svg>
</label>
<button aria-label="Clear" class="md-search__icon md-icon" data-md-component="search-reset" tabindex="-1" type="reset">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M19 6.41L17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41z"></path></svg>
</button>
</form>
<div class="md-search__output">
<div class="md-search__scrollwrap" data-md-scrollfix="">
<div class="md-search-result" data-md-component="search-result">
<div class="md-search-result__meta">
            Initializing search
          </div>
<ol class="md-search-result__list"></ol>
</div>
</div>
</div>
</div>
</div>
<div class="md-header-nav__source">
<a class="md-source" href="https://github.com/poets-ai/elegy/" title="Go to repository">
<div class="md-source__icon md-icon">
<svg viewbox="0 0 16 16" xmlns="http://www.w3.org/2000/svg"><path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z" fill-rule="evenodd"></path></svg>
</div>
<div class="md-source__repository">
    poets-ai/elegy
  </div>
</a>
</div>
</nav>
</header>
<div class="md-container" data-md-component="container">
<main class="md-main" data-md-component="main">
<div class="md-main__inner md-grid">
<div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
<div class="md-sidebar__scrollwrap">
<div class="md-sidebar__inner">
<nav aria-label="Navigation" class="md-nav md-nav--primary" data-md-level="0">
<label class="md-nav__title" for="__drawer">
<a aria-label="Elegy" class="md-nav__button md-logo" href="https://poets-ai.github.io/elegy" title="Elegy">
<svg viewbox="0 0 640 512" xmlns="http://www.w3.org/2000/svg"><path d="M471.1 96C405 96 353.3 137.3 320 174.6 286.7 137.3 235 96 168.9 96 75.8 96 0 167.8 0 256s75.8 160 168.9 160c66.1 0 117.8-41.3 151.1-78.6 33.3 37.3 85 78.6 151.1 78.6 93.1 0 168.9-71.8 168.9-160S564.2 96 471.1 96zM168.9 320c-40.2 0-72.9-28.7-72.9-64s32.7-64 72.9-64c38.2 0 73.4 36.1 94 64-20.4 27.6-55.9 64-94 64zm302.2 0c-38.2 0-73.4-36.1-94-64 20.4-27.6 55.9-64 94-64 40.2 0 72.9 28.7 72.9 64s-32.7 64-72.9 64z"></path></svg>
</a>
    Elegy
  </label>
<div class="md-nav__source">
<a class="md-source" href="https://github.com/poets-ai/elegy/" title="Go to repository">
<div class="md-source__icon md-icon">
<svg viewbox="0 0 16 16" xmlns="http://www.w3.org/2000/svg"><path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z" fill-rule="evenodd"></path></svg>
</div>
<div class="md-source__repository">
    poets-ai/elegy
  </div>
</a>
</div>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../.." title="Introduction">
      Introduction
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../getting-started/" title="Getting Started">
      Getting Started
    </a>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" data-md-toggle="nav-3" id="nav-3" type="checkbox"/>
<label class="md-nav__link" for="nav-3">
      Guides
      <span class="md-nav__icon md-icon">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"></path></svg>
</span>
</label>
<nav aria-label="Guides" class="md-nav" data-md-level="1">
<label class="md-nav__title" for="nav-3">
<span class="md-nav__icon md-icon">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"></path></svg>
</span>
        Guides
      </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../../guides/modules-losses-metrics/" title="Modules, Losses, and Metrics">
      Modules, Losses, and Metrics
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../guides/contributing/" title="Contibuting">
      Contibuting
    </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--active md-nav__item--nested">
<input checked="" class="md-nav__toggle md-toggle" data-md-toggle="nav-4" id="nav-4" type="checkbox"/>
<label class="md-nav__link" for="nav-4">
      API Reference
      <span class="md-nav__icon md-icon">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"></path></svg>
</span>
</label>
<nav aria-label="API Reference" class="md-nav" data-md-level="1">
<label class="md-nav__title" for="nav-4">
<span class="md-nav__icon md-icon">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"></path></svg>
</span>
        API Reference
      </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" data-md-toggle="nav-4-1" id="nav-4-1" type="checkbox"/>
<label class="md-nav__link" for="nav-4-1">
      module
      <span class="md-nav__icon md-icon">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"></path></svg>
</span>
</label>
<nav aria-label="module" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="nav-4-1">
<span class="md-nav__icon md-icon">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"></path></svg>
</span>
        module
      </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../module/Module/" title="Module">
      Module
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../module/Defered/" title="Defered">
      Defered
    </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--active md-nav__item--nested">
<input checked="" class="md-nav__toggle md-toggle" data-md-toggle="nav-4-2" id="nav-4-2" type="checkbox"/>
<label class="md-nav__link" for="nav-4-2">
      model
      <span class="md-nav__icon md-icon">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"></path></svg>
</span>
</label>
<nav aria-label="model" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="nav-4-2">
<span class="md-nav__icon md-icon">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"></path></svg>
</span>
        model
      </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item md-nav__item--active">
<input class="md-nav__toggle md-toggle" data-md-toggle="toc" id="__toc" type="checkbox"/>
<label class="md-nav__link md-nav__link--active" for="__toc">
        Model
        <span class="md-nav__icon md-icon">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M3 9h14V7H3v2m0 4h14v-2H3v2m0 4h14v-2H3v2m16 0h2v-2h-2v2m0-10v2h2V7h-2m0 6h2v-2h-2v2z"></path></svg>
</span>
</label>
<a class="md-nav__link md-nav__link--active" href="./" title="Model">
      Model
    </a>
<nav aria-label="Table of contents" class="md-nav md-nav--secondary">
<label class="md-nav__title" for="__toc">
<span class="md-nav__icon md-icon">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"></path></svg>
</span>
      Table of contents
    </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="#elegy.model.Model">
    elegy.model.Model
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#elegy.model.Model.seed">
    seed
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#elegy.model.Model.__init__">
    __init__()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#elegy.model.Model.evaluate">
    evaluate()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#elegy.model.Model.fit">
    fit()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#elegy.model.Model.load">
    load()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#elegy.model.Model.predict">
    predict()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#elegy.model.Model.predict_on_batch">
    predict_on_batch()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#elegy.model.Model.save">
    save()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#elegy.model.Model.summary">
    summary()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#elegy.model.Model.test_on_batch">
    test_on_batch()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#elegy.model.Model.train_on_batch">
    train_on_batch()
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../load/" title="load">
      load
    </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" data-md-toggle="nav-4-3" id="nav-4-3" type="checkbox"/>
<label class="md-nav__link" for="nav-4-3">
      hooks
      <span class="md-nav__icon md-icon">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"></path></svg>
</span>
</label>
<nav aria-label="hooks" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="nav-4-3">
<span class="md-nav__icon md-icon">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"></path></svg>
</span>
        hooks
      </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../hooks/add_loss/" title="add_loss">
      add_loss
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../hooks/add_metric/" title="add_metric">
      add_metric
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../hooks/add_summary/" title="add_summary">
      add_summary
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../hooks/transform/" title="transform">
      transform
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../hooks/TransformedState/" title="TransformedState">
      TransformedState
    </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" data-md-toggle="nav-4-4" id="nav-4-4" type="checkbox"/>
<label class="md-nav__link" for="nav-4-4">
      nn
      <span class="md-nav__icon md-icon">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"></path></svg>
</span>
</label>
<nav aria-label="nn" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="nav-4-4">
<span class="md-nav__icon md-icon">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"></path></svg>
</span>
        nn
      </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../nn/Linear/" title="Linear">
      Linear
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../nn/Conv2D/" title="Conv2D">
      Conv2D
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../nn/Flatten/" title="Flatten">
      Flatten
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../nn/BatchNormalization/" title="BatchNormalization">
      BatchNormalization
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../nn/Dropout/" title="Dropout">
      Dropout
    </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" data-md-toggle="nav-4-5" id="nav-4-5" type="checkbox"/>
<label class="md-nav__link" for="nav-4-5">
      metrics
      <span class="md-nav__icon md-icon">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"></path></svg>
</span>
</label>
<nav aria-label="metrics" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="nav-4-5">
<span class="md-nav__icon md-icon">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"></path></svg>
</span>
        metrics
      </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../metrics/Metric/" title="Metric">
      Metric
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../metrics/Accuracy/" title="Accuracy">
      Accuracy
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../metrics/BinaryCrossentropy/" title="BinaryCrossentropy">
      BinaryCrossentropy
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../metrics/CategoricalAccuracy/" title="CategoricalAccuracy">
      CategoricalAccuracy
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../metrics/SparseCategoricalAccuracy/" title="SparseCategoricalAccuracy">
      SparseCategoricalAccuracy
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../metrics/Mean/" title="Mean">
      Mean
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../metrics/MeanAbsoluteError/" title="MeanAbsoluteError">
      MeanAbsoluteError
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../metrics/MeanSquaredError/" title="MeanSquaredError">
      MeanSquaredError
    </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" data-md-toggle="nav-4-6" id="nav-4-6" type="checkbox"/>
<label class="md-nav__link" for="nav-4-6">
      losses
      <span class="md-nav__icon md-icon">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"></path></svg>
</span>
</label>
<nav aria-label="losses" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="nav-4-6">
<span class="md-nav__icon md-icon">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"></path></svg>
</span>
        losses
      </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../losses/Loss/" title="Loss">
      Loss
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../losses/BinaryCrossentropy/" title="BinaryCrossentropy">
      BinaryCrossentropy
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../losses/CategoricalCrossentropy/" title="CategoricalCrossentropy">
      CategoricalCrossentropy
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../losses/SparseCategoricalCrossentropy/" title="SparseCategoricalCrossentropy">
      SparseCategoricalCrossentropy
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../losses/MeanAbsoluteError/" title="MeanAbsoluteError">
      MeanAbsoluteError
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../losses/MeanSquaredError/" title="MeanSquaredError">
      MeanSquaredError
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../losses/mean_squared_error/" title="mean_squared_error">
      mean_squared_error
    </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" data-md-toggle="nav-4-7" id="nav-4-7" type="checkbox"/>
<label class="md-nav__link" for="nav-4-7">
      regularizers
      <span class="md-nav__icon md-icon">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"></path></svg>
</span>
</label>
<nav aria-label="regularizers" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="nav-4-7">
<span class="md-nav__icon md-icon">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"></path></svg>
</span>
        regularizers
      </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../regularizers/GlobalL1/" title="GlobalL1">
      GlobalL1
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../regularizers/GlobalL2/" title="GlobalL2">
      GlobalL2
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../regularizers/GlobalL1L2/" title="GlobalL1L2">
      GlobalL1L2
    </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" data-md-toggle="nav-4-8" id="nav-4-8" type="checkbox"/>
<label class="md-nav__link" for="nav-4-8">
      callbacks
      <span class="md-nav__icon md-icon">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"></path></svg>
</span>
</label>
<nav aria-label="callbacks" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="nav-4-8">
<span class="md-nav__icon md-icon">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"></path></svg>
</span>
        callbacks
      </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../callbacks/Callback/" title="Callback">
      Callback
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../callbacks/ModelCheckpoint/" title="ModelCheckpoint">
      ModelCheckpoint
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../callbacks/EarlyStopping/" title="EarlyStopping">
      EarlyStopping
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../callbacks/LambdaCallback/" title="LambdaCallback">
      LambdaCallback
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../callbacks/CSVLogger/" title="CSVLogger">
      CSVLogger
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../callbacks/RemoteMonitor/" title="RemoteMonitor">
      RemoteMonitor
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../callbacks/TerminateOnNaN/" title="TerminateOnNaN">
      TerminateOnNaN
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../callbacks/TensorBoard/" title="Tensorboard">
      Tensorboard
    </a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</div>
</div>
</div>
<div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
<div class="md-sidebar__scrollwrap">
<div class="md-sidebar__inner">
<nav aria-label="Table of contents" class="md-nav md-nav--secondary">
<label class="md-nav__title" for="__toc">
<span class="md-nav__icon md-icon">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"></path></svg>
</span>
      Table of contents
    </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="#elegy.model.Model">
    elegy.model.Model
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#elegy.model.Model.seed">
    seed
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#elegy.model.Model.__init__">
    __init__()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#elegy.model.Model.evaluate">
    evaluate()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#elegy.model.Model.fit">
    fit()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#elegy.model.Model.load">
    load()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#elegy.model.Model.predict">
    predict()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#elegy.model.Model.predict_on_batch">
    predict_on_batch()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#elegy.model.Model.save">
    save()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#elegy.model.Model.summary">
    summary()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#elegy.model.Model.test_on_batch">
    test_on_batch()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#elegy.model.Model.train_on_batch">
    train_on_batch()
  </a>
</li>
</ul>
</nav>
</div>
</div>
</div>
<div class="md-content">
<article class="md-content__inner md-typeset">
<a class="md-content__button md-icon" href="https://github.com/poets-ai/elegy/edit/master/docs/api/model/Model.md" title="Edit this page">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25z"></path></svg>
</a>
<h1 id="elegymodel">elegy.Model</h1>
<div class="doc doc-object doc-class">
<h2 class="hidden-toc" href="#elegy.model.Model" id="elegy.model.Model" style="visibility: hidden; width: 0; height: 0;">
</h2>
<div class="doc doc-contents first">
<p><code>Model</code> is tasked with performing training, evaluation, and inference for a given
<code>elegy.Module</code> or <code>haiku.Module</code>.</p>
<p>To create a <code>Model</code> you first have to define its architecture in a <code>Module</code>:</p>
<div class="codehilite">
<pre><span></span><code><span class="k">class</span> <span class="nc">MLP</span><span class="p">(</span><span class="n">elegy</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__apply__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">image</span><span class="p">:</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
        <span class="n">mlp</span> <span class="o">=</span> <span class="n">hk</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
            <span class="n">hk</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(),</span>
            <span class="n">hk</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">300</span><span class="p">),</span>
            <span class="n">jax</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">,</span>
            <span class="n">hk</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span>
        <span class="p">])</span>
        <span class="k">return</span> <span class="n">mlp</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
</code></pre>
</div>
<p>Then you can pass this <code>Module</code> to the <code>Model</code>'s constructor and specify additional things like losses, metrics, optimizer, and callbacks:</p>
<div class="codehilite">
<pre><span></span><code><span class="n">model</span> <span class="o">=</span> <span class="n">elegy</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span>
    <span class="n">module</span><span class="o">=</span><span class="n">MLP</span><span class="o">.</span><span class="n">defer</span><span class="p">(),</span>
    <span class="n">loss</span><span class="o">=</span><span class="p">[</span>
        <span class="n">elegy</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">SparseCategoricalCrossentropy</span><span class="p">(</span><span class="n">from_logits</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
        <span class="n">elegy</span><span class="o">.</span><span class="n">regularizers</span><span class="o">.</span><span class="n">GlobalL2</span><span class="p">(</span><span class="n">l</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">),</span>
    <span class="p">],</span>
    <span class="n">metrics</span><span class="o">=</span><span class="n">elegy</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">SparseCategoricalAccuracy</span><span class="o">.</span><span class="n">defer</span><span class="p">(),</span>
    <span class="n">optimizer</span><span class="o">=</span><span class="n">optix</span><span class="o">.</span><span class="n">rmsprop</span><span class="p">(</span><span class="mf">1e-3</span><span class="p">),</span>
<span class="p">)</span>
</code></pre>
</div>
<p>Once the model is created, you can train the model with <code>model.fit()</code>, or use the model
to do prediction with <code>model.predict()</code>.
Checkout <a href="https://poets-ai.github.io/elegy/getting-started">Getting Started</a> for
additional details.</p>
<p><strong>Attributes:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>params</code></td>
<td><code>Optional[Mapping[str, Mapping[str, jax.numpy.lax_numpy.ndarray]]]</code></td>
<td>
<p>A <code>haiku.Params</code> structure with the weights of the model.</p>
</td>
</tr>
<tr>
<td><code>state</code></td>
<td><code>Optional[Mapping[str, Mapping[str, jax.numpy.lax_numpy.ndarray]]]</code></td>
<td>
<p>A <code>haiku.State</code> structure with non-trainable parameters of the model.</p>
</td>
</tr>
<tr>
<td><code>optimizer_state</code></td>
<td><code>Optional[NamedTuple]</code></td>
<td>
<p>A <code>optix.OptState</code> structure with state of the optimizer.</p>
</td>
</tr>
<tr>
<td><code>metrics_state</code></td>
<td><code>Optional[Mapping[str, Mapping[str, jax.numpy.lax_numpy.ndarray]]]</code></td>
<td>
<p>A <code>haiku.State</code> structure with the state of the metrics.</p>
</td>
</tr>
<tr>
<td><code>initial_metrics_state</code></td>
<td><code>Optional[Mapping[str, Mapping[str, jax.numpy.lax_numpy.ndarray]]]</code></td>
<td>
<p>A <code>haiku.State</code> structure with the initial state of the metrics.</p>
</td>
</tr>
<tr>
<td><code>run_eagerly</code></td>
<td><code>bool</code></td>
<td>
<p>Settable attribute indicating whether the model should run eagerly.
Running eagerly means that your model will be run step by step, like Python code, instead of
using Jax's <code>jit</code> to optimize the computation. Your model might run slower, but it should become easier for you to debug 
it by stepping into individual layer calls.</p>
</td>
</tr>
</tbody>
</table>
<div class="doc doc-children">
<div class="doc doc-object doc-attribute">
<h2 class="doc doc-heading" id="elegy.model.Model.seed">
<code class="highlight">
seed: <span class="n">Union</span><span class="p">[</span><span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-property"><code>property</code></small>
<small class="doc doc-property doc-property-writable"><code>writable</code></small>
</span>
</h2>
<div class="doc doc-contents">
<p>Current random state of the model.</p>
</div>
</div>
<div class="doc doc-object doc-method">
<h2 class="doc doc-heading" id="elegy.model.Model.__init__">
<code class="highlight language-python">
__init__<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">module</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">run_eagerly</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">state</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">optimizer_state</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">metrics_state</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">initial_metrics_state</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
</h2>
<div class="doc doc-contents">
<p>[summary]</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>module</code></td>
<td><code>Callable</code></td>
<td>
<p>A 0-argument function that returns a Haiku or Elegy <code>Module</code> instance.</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>loss</code></td>
<td><code>Optional[Union[Callable, List, Dict]]</code></td>
<td>
<p>A <code>elegy.Loss</code> or <code>Callable</code> instance representing the loss function of the network.
You can define more loss terms by simply passing a possibly nested structure of
lists and dictionaries of <code>elegy.Loss</code> or <code>Callable</code>s. Usually a plain list of losses is enough
but using dictionaries will create namescopes for the names of the losses
which might be useful e.g. to group things in tensorboard. Contrary to Keras convention,
in Elegy there is no relation between the structure of <code>loss</code> with the structure
of the labels and outputs of the network. Elegy's loss system is more flexible than
the one provided by Keras, for more information on how to mimick Keras behavior checkout the 
<a href="https://poets-ai.github.io/elegy/guides/losses-and-metrics">Losses and Metrics Guide</a>`.</p>
</td>
<td><code>None</code></td>
</tr>
<tr>
<td><code>metrics</code></td>
<td><code>Optional[Union[Callable, List, Dict]]</code></td>
<td>
<p>A <code>elegy.Metric</code> or <code>Callable</code> instance representing the loss function of the network.
You can define more metrics terms by simply passing a possibly nested structure of
lists and dictionaries of <code>elegy.Metric</code> or <code>Callable</code>s. Usually a plain list of metrics is enough
but using dictionaries will create namescopes for the names of the metrics
which might be useful e.g. to group things in tensorboard. Contrary to Keras convention,
in Elegy there is no relation between the structure of <code>metrics</code> with the structure
of the labels and outputs of the network. Elegy's metrics system is more flexible than
the one provided by Keras, for more information on how to mimick Keras behavior checkout the 
<a href="https://poets-ai.github.io/elegy/guides/losses-and-metrics">Losses and Metrics Guide</a>`.</p>
</td>
<td><code>None</code></td>
</tr>
<tr>
<td><code>optimizer</code></td>
<td><code>Optional[jax.experimental.optix.GradientTransformation]</code></td>
<td>
<p>A <code>optix</code> optimizer instance. Optix is a very flexible library for defining
optimization pipelines with things like learning rate schedules, this means that
there is no need for a <code>LearningRateScheduler</code> callback in Elegy.</p>
</td>
<td><code>None</code></td>
</tr>
<tr>
<td><code>run_eagerly</code></td>
<td><code>bool</code></td>
<td>
<p>Settable attribute indicating whether the model should run eagerly.
Running eagerly means that your model will be run step by step, like Python code, instead of
using Jax's <code>jit</code> to. Your model might run slower, but it should become easier for you to debug 
it by stepping into individual layer calls.</p>
</td>
<td><code>False</code></td>
</tr>
<tr>
<td><code>params</code></td>
<td><code>Optional[Mapping[str, Mapping[str, jax.numpy.lax_numpy.ndarray]]]</code></td>
<td>
<p>A <code>haiku.Params</code> structure with the weights of the model.</p>
</td>
<td><code>None</code></td>
</tr>
<tr>
<td><code>state</code></td>
<td><code>Optional[Mapping[str, Mapping[str, jax.numpy.lax_numpy.ndarray]]]</code></td>
<td>
<p>A <code>haiku.State</code> structure with non-trainable parameters of the model.</p>
</td>
<td><code>None</code></td>
</tr>
<tr>
<td><code>optimizer_state</code></td>
<td><code>Optional[NamedTuple]</code></td>
<td>
<p>A <code>optix.OptState</code> structure with state of the optimizer.</p>
</td>
<td><code>None</code></td>
</tr>
<tr>
<td><code>metrics_state</code></td>
<td><code>Optional[Mapping[str, Mapping[str, jax.numpy.lax_numpy.ndarray]]]</code></td>
<td>
<p>A <code>haiku.State</code> structure with the state of the metrics.</p>
</td>
<td><code>None</code></td>
</tr>
<tr>
<td><code>initial_metrics_state</code></td>
<td><code>Optional[Mapping[str, Mapping[str, jax.numpy.lax_numpy.ndarray]]]</code></td>
<td>
<p>A <code>haiku.State</code> structure with the initial state of the metrics.</p>
</td>
<td><code>None</code></td>
</tr>
<tr>
<td><code>seed</code></td>
<td><code>Union[numpy.ndarray, int]</code></td>
<td>
<p>The initial random state of the model.</p>
</td>
<td><code>42</code></td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>elegy/model.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">module</span><span class="p">:</span> <span class="n">tp</span><span class="o">.</span><span class="n">Callable</span><span class="p">,</span>
    <span class="n">loss</span><span class="p">:</span> <span class="n">tp</span><span class="o">.</span><span class="n">Union</span><span class="p">[</span><span class="n">tp</span><span class="o">.</span><span class="n">Callable</span><span class="p">,</span> <span class="n">tp</span><span class="o">.</span><span class="n">List</span><span class="p">,</span> <span class="n">tp</span><span class="o">.</span><span class="n">Dict</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">metrics</span><span class="p">:</span> <span class="n">tp</span><span class="o">.</span><span class="n">Union</span><span class="p">[</span><span class="n">tp</span><span class="o">.</span><span class="n">Callable</span><span class="p">,</span> <span class="n">tp</span><span class="o">.</span><span class="n">List</span><span class="p">,</span> <span class="n">tp</span><span class="o">.</span><span class="n">Dict</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">optimizer</span><span class="p">:</span> <span class="n">tp</span><span class="o">.</span><span class="n">Optional</span><span class="p">[</span><span class="n">optix</span><span class="o">.</span><span class="n">GradientTransformation</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">run_eagerly</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">params</span><span class="p">:</span> <span class="n">tp</span><span class="o">.</span><span class="n">Optional</span><span class="p">[</span><span class="n">hk</span><span class="o">.</span><span class="n">Params</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">state</span><span class="p">:</span> <span class="n">tp</span><span class="o">.</span><span class="n">Optional</span><span class="p">[</span><span class="n">hk</span><span class="o">.</span><span class="n">State</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">optimizer_state</span><span class="p">:</span> <span class="n">tp</span><span class="o">.</span><span class="n">Optional</span><span class="p">[</span><span class="n">optix</span><span class="o">.</span><span class="n">OptState</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">metrics_state</span><span class="p">:</span> <span class="n">tp</span><span class="o">.</span><span class="n">Optional</span><span class="p">[</span><span class="n">hk</span><span class="o">.</span><span class="n">State</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">initial_metrics_state</span><span class="p">:</span> <span class="n">tp</span><span class="o">.</span><span class="n">Optional</span><span class="p">[</span><span class="n">hk</span><span class="o">.</span><span class="n">State</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">seed</span><span class="p">:</span> <span class="n">tp</span><span class="o">.</span><span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="mi">42</span><span class="p">,</span>
<span class="p">):</span>
    <span class="sd">"""[summary]</span>

<span class="sd">    Arguments:</span>
<span class="sd">        module: A 0-argument function that returns a Haiku or Elegy `Module` instance.</span>
<span class="sd">        loss: A `elegy.Loss` or `Callable` instance representing the loss function of the network.</span>
<span class="sd">            You can define more loss terms by simply passing a possibly nested structure of</span>
<span class="sd">            lists and dictionaries of `elegy.Loss` or `Callable`s. Usually a plain list of losses is enough</span>
<span class="sd">            but using dictionaries will create namescopes for the names of the losses</span>
<span class="sd">            which might be useful e.g. to group things in tensorboard. Contrary to Keras convention,</span>
<span class="sd">            in Elegy there is no relation between the structure of `loss` with the structure</span>
<span class="sd">            of the labels and outputs of the network. Elegy's loss system is more flexible than</span>
<span class="sd">            the one provided by Keras, for more information on how to mimick Keras behavior checkout the </span>
<span class="sd">            [Losses and Metrics Guide](https://poets-ai.github.io/elegy/guides/losses-and-metrics)`.</span>
<span class="sd">        metrics: A `elegy.Metric` or `Callable` instance representing the loss function of the network.</span>
<span class="sd">            You can define more metrics terms by simply passing a possibly nested structure of</span>
<span class="sd">            lists and dictionaries of `elegy.Metric` or `Callable`s. Usually a plain list of metrics is enough</span>
<span class="sd">            but using dictionaries will create namescopes for the names of the metrics</span>
<span class="sd">            which might be useful e.g. to group things in tensorboard. Contrary to Keras convention,</span>
<span class="sd">            in Elegy there is no relation between the structure of `metrics` with the structure</span>
<span class="sd">            of the labels and outputs of the network. Elegy's metrics system is more flexible than</span>
<span class="sd">            the one provided by Keras, for more information on how to mimick Keras behavior checkout the </span>
<span class="sd">            [Losses and Metrics Guide](https://poets-ai.github.io/elegy/guides/losses-and-metrics)`.</span>
<span class="sd">        optimizer: A `optix` optimizer instance. Optix is a very flexible library for defining</span>
<span class="sd">            optimization pipelines with things like learning rate schedules, this means that</span>
<span class="sd">            there is no need for a `LearningRateScheduler` callback in Elegy.</span>
<span class="sd">        run_eagerly: Settable attribute indicating whether the model should run eagerly.</span>
<span class="sd">            Running eagerly means that your model will be run step by step, like Python code, instead of</span>
<span class="sd">            using Jax's `jit` to. Your model might run slower, but it should become easier for you to debug </span>
<span class="sd">            it by stepping into individual layer calls.</span>
<span class="sd">        params: A `haiku.Params` structure with the weights of the model.</span>
<span class="sd">        state: A `haiku.State` structure with non-trainable parameters of the model.</span>
<span class="sd">        optimizer_state:  A `optix.OptState` structure with state of the optimizer.</span>
<span class="sd">        metrics_state: A `haiku.State` structure with the state of the metrics.</span>
<span class="sd">        initial_metrics_state: A `haiku.State` structure with the initial state of the metrics.</span>
<span class="sd">        seed: The initial random state of the model.</span>
<span class="sd">    """</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_module_fn</span> <span class="o">=</span> <span class="n">module</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_model_transform</span> <span class="o">=</span> <span class="n">hooks</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_module_fn</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_loss_fn</span> <span class="o">=</span> <span class="n">loss_modes</span><span class="o">.</span><span class="n">forward_all</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span> <span class="k">if</span> <span class="n">loss</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_metrics_transform</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">hk</span><span class="o">.</span><span class="n">transform_with_state</span><span class="p">(</span>
            <span class="n">utils</span><span class="o">.</span><span class="n">inject_dependencies</span><span class="p">(</span>
                <span class="n">metric_modes</span><span class="o">.</span><span class="n">forward_all</span><span class="p">(</span><span class="n">metrics</span><span class="p">),</span>
                <span class="n">rename</span><span class="o">=</span><span class="p">{</span><span class="s2">"__params"</span><span class="p">:</span> <span class="s2">"params"</span><span class="p">,</span> <span class="s2">"__state"</span><span class="p">:</span> <span class="s2">"state"</span><span class="p">},</span>
            <span class="p">)</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="n">metrics</span>
        <span class="k">else</span> <span class="kc">None</span>
    <span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_optimizer</span> <span class="o">=</span> <span class="n">optimizer</span> <span class="k">if</span> <span class="n">optimizer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">optix</span><span class="o">.</span><span class="n">adam</span><span class="p">(</span><span class="mf">1e-3</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_rngs</span> <span class="o">=</span> <span class="n">hk</span><span class="o">.</span><span class="n">PRNGSequence</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">params</span> <span class="o">=</span> <span class="n">params</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">state</span> <span class="o">=</span> <span class="n">state</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">optimizer_state</span> <span class="o">=</span> <span class="n">optimizer_state</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">metrics_state</span> <span class="o">=</span> <span class="n">metrics_state</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">initial_metrics_state</span> <span class="o">=</span> <span class="n">initial_metrics_state</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">run_eagerly</span> <span class="o">=</span> <span class="n">run_eagerly</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h2 class="doc doc-heading" id="elegy.model.Model.evaluate">
<code class="highlight language-python">
evaluate<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">steps</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> </code>
</h2>
<div class="doc doc-contents">
<p>Returns the loss value &amp; metrics values for the model in test mode.
Computation is done in batches.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>x</code></td>
<td><code>Union[numpy.ndarray, Mapping[str, numpy.ndarray], Tuple[numpy.ndarray], Iterable]</code></td>
<td>
<p>Input data. It could be:</p>
<ul>
<li>A Numpy or Jax array (or array-like), or a list of arrays
    (in case the model has multiple inputs).</li>
<li>A dict mapping input names to the corresponding arrays,
    if the model has named inputs.</li>
<li>A generator returning <code>(inputs,)</code>, <code>(inputs, targets)</code>
    or <code>(inputs, targets, sample_weights)</code>.</li>
</ul>
<p>A more detailed description of
unpacking behavior for iterator types generator
is given in the <code>Unpacking behavior for iterator-like inputs</code> section
of <code>Model.fit</code>.</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>y</code></td>
<td><code>Optional[Union[jax.numpy.lax_numpy.ndarray, numpy.ndarray, Mapping[str, numpy.ndarray], Tuple[numpy.ndarray]]]</code></td>
<td>
<p>Target data. Like the input data <code>x</code>,
it could be either Numpy or Jax array(s).
It should be consistent with <code>x</code>. If <code>x</code> is a generator,
<code>y</code> should not be specified (since targets will be obtained from <code>x</code>).</p>
</td>
<td><code>None</code></td>
</tr>
<tr>
<td><code>verbose</code></td>
<td><code>int</code></td>
<td>
<p>0, 1, or 2. Verbosity mode.
0 = silent, 1 = progress bar, 2 = one line per epoch.</p>
</td>
<td><code>1</code></td>
</tr>
<tr>
<td><code>batch_size</code></td>
<td><code>Optional[int]</code></td>
<td>
<p>Integer or <code>None</code>.
Number of samples per gradient update.
If unspecified, <code>batch_size</code> will default to 32.
Do not specify the <code>batch_size</code> if your data is in the
form of generator (since they generate batches).</p>
</td>
<td><code>None</code></td>
</tr>
<tr>
<td><code>sample_weight</code></td>
<td><code>Optional[numpy.ndarray]</code></td>
<td>
<p>Optional Numpy/Jax array of weights for
the training samples, used for weighting the loss function
(during training only). You can either pass a flat (1D)
Numpy array with the same length as the input samples
(1:1 mapping between weights and samples). This argument is not
supported when <code>x</code> is generator, instead provide the sample_weights
as the third element of <code>x</code>.</p>
</td>
<td><code>None</code></td>
</tr>
<tr>
<td><code>steps</code></td>
<td><code>Optional[int]</code></td>
<td>
<p>Integer or <code>None</code>. Total number of steps (batches of samples)
before declaring the evaluation round finished. Ignored with the
default value of <code>None</code>. This
argument is not supported with array inputs.</p>
</td>
<td><code>None</code></td>
</tr>
<tr>
<td><code>callbacks</code></td>
<td><code>Optional[Union[List[elegy.callbacks.callback.Callback], elegy.callbacks.callback_list.CallbackList]]</code></td>
<td>
<p>List of <a href="https://poets-ai.github.io/elegy/api/callbacks/Callback/#elegy.callbacks.callback.Callback">elegy.callbacks.callback.Callback</a> instances.
List of callbacks to apply during training.</p>
</td>
<td><code>None</code></td>
</tr>
</tbody>
</table>
<p>See the discussion of <code>Unpacking behavior for iterator-like inputs</code> for
 <a href="https://poets-ai.github.io/elegy/api/model/Model/#elegy.model.Model.fit"><code>Model.fit</code></a>.</p>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>Dict[str, numpy.ndarray]</code></td>
<td>
<p>A dictionary for mapping the losses and metrics names to the values obtained.</p>
</td>
</tr>
</tbody>
</table>
<p><strong>Exceptions:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>ValueError</code></td>
<td>
<p>in case of invalid arguments.</p>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>elegy/model.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>725
726
727
728
729
730
731
732
733
734
735
736
737
738
739
740
741
742
743
744
745
746
747
748
749
750
751
752
753
754
755
756
757
758
759
760
761
762
763
764
765
766
767
768
769
770
771
772
773
774
775
776
777
778
779
780
781
782
783
784
785
786
787
788
789
790
791
792
793
794
795
796
797
798
799
800
801
802
803
804
805
806
807
808
809
810
811
812
813
814
815
816
817
818
819
820
821
822
823
824
825
826
827
828
829
830
831
832
833
834
835
836
837
838</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">evaluate</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">tp</span><span class="o">.</span><span class="n">Union</span><span class="p">[</span>
        <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">tp</span><span class="o">.</span><span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span> <span class="n">tp</span><span class="o">.</span><span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span> <span class="n">tp</span><span class="o">.</span><span class="n">Iterable</span><span class="p">,</span>
    <span class="p">],</span>
    <span class="n">y</span><span class="p">:</span> <span class="n">tp</span><span class="o">.</span><span class="n">Union</span><span class="p">[</span>
        <span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
        <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
        <span class="n">tp</span><span class="o">.</span><span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span>
        <span class="n">tp</span><span class="o">.</span><span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span>
        <span class="kc">None</span><span class="p">,</span>
    <span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">verbose</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="p">:</span> <span class="n">tp</span><span class="o">.</span><span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">sample_weight</span><span class="p">:</span> <span class="n">tp</span><span class="o">.</span><span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">steps</span><span class="p">:</span> <span class="n">tp</span><span class="o">.</span><span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">callbacks</span><span class="p">:</span> <span class="n">tp</span><span class="o">.</span><span class="n">Union</span><span class="p">[</span><span class="n">tp</span><span class="o">.</span><span class="n">List</span><span class="p">[</span><span class="n">Callback</span><span class="p">],</span> <span class="n">CallbackList</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">tp</span><span class="o">.</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]:</span>
    <span class="sd">"""Returns the loss value &amp; metrics values for the model in test mode.</span>
<span class="sd">        Computation is done in batches.</span>

<span class="sd">        Arguments:</span>
<span class="sd">            x: Input data. It could be:</span>

<span class="sd">                - A Numpy or Jax array (or array-like), or a list of arrays</span>
<span class="sd">                    (in case the model has multiple inputs).</span>
<span class="sd">                - A dict mapping input names to the corresponding arrays,</span>
<span class="sd">                    if the model has named inputs.</span>
<span class="sd">                - A generator returning `(inputs,)`, `(inputs, targets)`</span>
<span class="sd">                    or `(inputs, targets, sample_weights)`.</span>

<span class="sd">                A more detailed description of</span>
<span class="sd">                unpacking behavior for iterator types generator</span>
<span class="sd">                is given in the `Unpacking behavior for iterator-like inputs` section</span>
<span class="sd">                of `Model.fit`.</span>
<span class="sd">            y: Target data. Like the input data `x`,</span>
<span class="sd">                it could be either Numpy or Jax array(s).</span>
<span class="sd">                It should be consistent with `x`. If `x` is a generator,</span>
<span class="sd">                `y` should not be specified (since targets will be obtained from `x`).</span>
<span class="sd">            verbose: 0, 1, or 2. Verbosity mode.</span>
<span class="sd">                0 = silent, 1 = progress bar, 2 = one line per epoch.</span>
<span class="sd">            batch_size: Integer or `None`.</span>
<span class="sd">                Number of samples per gradient update.</span>
<span class="sd">                If unspecified, `batch_size` will default to 32.</span>
<span class="sd">                Do not specify the `batch_size` if your data is in the</span>
<span class="sd">                form of generator (since they generate batches).</span>
<span class="sd">            sample_weight: Optional Numpy/Jax array of weights for</span>
<span class="sd">                the training samples, used for weighting the loss function</span>
<span class="sd">                (during training only). You can either pass a flat (1D)</span>
<span class="sd">                Numpy array with the same length as the input samples</span>
<span class="sd">                (1:1 mapping between weights and samples). This argument is not</span>
<span class="sd">                supported when `x` is generator, instead provide the sample_weights</span>
<span class="sd">                as the third element of `x`.</span>
<span class="sd">            steps: Integer or `None`. Total number of steps (batches of samples)</span>
<span class="sd">                before declaring the evaluation round finished. Ignored with the</span>
<span class="sd">                default value of `None`. This</span>
<span class="sd">                argument is not supported with array inputs.</span>
<span class="sd">            callbacks: List of [elegy.callbacks.callback.Callback][] instances.</span>
<span class="sd">                List of callbacks to apply during training.</span>

<span class="sd">        See the discussion of `Unpacking behavior for iterator-like inputs` for</span>
<span class="sd">         [`Model.fit`][elegy.model.Model.fit].</span>

<span class="sd">        Returns:</span>
<span class="sd">            A dictionary for mapping the losses and metrics names to the values obtained.</span>
<span class="sd">        Raises:</span>
<span class="sd">            ValueError: in case of invalid arguments.</span>
<span class="sd">        """</span>

    <span class="n">data_handler</span> <span class="o">=</span> <span class="n">DataHandler</span><span class="p">(</span>
        <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span>
        <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span>
        <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
        <span class="n">steps_per_epoch</span><span class="o">=</span><span class="n">steps</span><span class="p">,</span>
        <span class="n">initial_epoch</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">is_training</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="c1"># Container that configures and calls `tf.keras.Callback`s.</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">callbacks</span><span class="p">,</span> <span class="n">CallbackList</span><span class="p">):</span>
        <span class="n">callbacks</span> <span class="o">=</span> <span class="n">CallbackList</span><span class="p">(</span>
            <span class="n">callbacks</span><span class="p">,</span>
            <span class="n">add_history</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">add_progbar</span><span class="o">=</span><span class="n">verbose</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">,</span>
            <span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="p">,</span>
            <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>
            <span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
            <span class="n">steps</span><span class="o">=</span><span class="n">data_handler</span><span class="o">.</span><span class="n">inferred_steps</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="n">callbacks</span><span class="o">.</span><span class="n">on_test_begin</span><span class="p">()</span>

    <span class="n">logs</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">iterator</span> <span class="ow">in</span> <span class="n">data_handler</span><span class="o">.</span><span class="n">enumerate_epochs</span><span class="p">():</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reset_metrics</span><span class="p">()</span>
        <span class="k">with</span> <span class="n">data_handler</span><span class="o">.</span><span class="n">catch_stop_iteration</span><span class="p">():</span>
            <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="n">data_handler</span><span class="o">.</span><span class="n">steps</span><span class="p">():</span>
                <span class="n">callbacks</span><span class="o">.</span><span class="n">on_test_batch_begin</span><span class="p">(</span><span class="n">step</span><span class="p">)</span>
                <span class="n">batch</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span>
                <span class="n">x_batch</span><span class="p">,</span> <span class="n">y_batch</span><span class="p">,</span> <span class="n">sample_weight</span> <span class="o">=</span> <span class="n">unpack_x_y_sample_weight</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>

                <span class="n">tmp_logs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">test_on_batch</span><span class="p">(</span>
                    <span class="n">x</span><span class="o">=</span><span class="n">x_batch</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y_batch</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="n">tmp_logs</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s2">"size"</span><span class="p">:</span> <span class="n">data_handler</span><span class="o">.</span><span class="n">batch_size</span><span class="p">})</span>
                <span class="n">logs</span> <span class="o">=</span> <span class="n">tmp_logs</span>
                <span class="n">callbacks</span><span class="o">.</span><span class="n">on_test_batch_end</span><span class="p">(</span><span class="n">step</span><span class="p">,</span> <span class="n">logs</span><span class="p">)</span>

    <span class="n">callbacks</span><span class="o">.</span><span class="n">on_test_end</span><span class="p">()</span>

    <span class="k">return</span> <span class="n">logs</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h2 class="doc doc-heading" id="elegy.model.Model.fit">
<code class="highlight language-python">
fit<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">validation_split</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">validation_data</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">class_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">initial_epoch</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">steps_per_epoch</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">validation_steps</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">validation_batch_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">validation_freq</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> </code>
</h2>
<div class="doc doc-contents">
<p>Trains the model for a fixed number of epochs (iterations on a dataset).</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>x</code></td>
<td><code>Union[numpy.ndarray, Mapping[str, numpy.ndarray], Tuple[numpy.ndarray], Iterable]</code></td>
<td>
<p>Input data. It could be:</p>
<ul>
<li>A Numpy or Jax array (or array-like), or a list of arrays
    (in case the model has multiple inputs).</li>
<li>A dict mapping input names to the corresponding arrays,
    if the model has named inputs.</li>
<li>A generator returning <code>(inputs,)</code>, <code>(inputs, targets)</code>
    or <code>(inputs, targets, sample_weights)</code>.</li>
</ul>
<p>A more detailed description of unpacking behavior for generator type
is given below.</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>y</code></td>
<td><code>Optional[Union[numpy.ndarray, Mapping[str, numpy.ndarray], Tuple[numpy.ndarray]]]</code></td>
<td>
<p>Target data. Like the input data <code>x</code>,
it could be either Numpy or Jax array(s).
It should be consistent with <code>x</code>. If <code>x</code> is a generator,
<code>y</code> should not be specified (since targets will be obtained from <code>x</code>).</p>
</td>
<td><code>None</code></td>
</tr>
<tr>
<td><code>batch_size</code></td>
<td><code>Optional[int]</code></td>
<td>
<p>Integer or <code>None</code>.
Number of samples per gradient update.
If unspecified, <code>batch_size</code> will default to 32.
Do not specify the <code>batch_size</code> if your data is in the
form of generator (since they generate batches).</p>
</td>
<td><code>None</code></td>
</tr>
<tr>
<td><code>epochs</code></td>
<td><code>int</code></td>
<td>
<p>Integer. Number of epochs to train the model.
An epoch is an iteration over the entire <code>x</code> and <code>y</code>
data provided.
Note that in conjunction with <code>initial_epoch</code>,
<code>epochs</code> is to be understood as "final epoch".
The model is not trained for a number of iterations
given by <code>epochs</code>, but merely until the epoch
of index <code>epochs</code> is reached.</p>
</td>
<td><code>1</code></td>
</tr>
<tr>
<td><code>verbose</code></td>
<td><code>int</code></td>
<td>
<p>0, 1, or 2. Verbosity mode.
0 = silent, 1 = progress bar, 2 = one line per epoch.
Note that the progress bar is not particularly useful when
logged to a file, so verbose=2 is recommended when not running
interactively (eg, in a production environment).</p>
</td>
<td><code>1</code></td>
</tr>
<tr>
<td><code>callbacks</code></td>
<td><code>Optional[Union[List[elegy.callbacks.callback.Callback], elegy.callbacks.callback_list.CallbackList]]</code></td>
<td>
<p>List of <a href="https://poets-ai.github.io/elegy/api/callbacks/Callback/#elegy.callbacks.callback.Callback">elegy.callbacks.callback.Callback</a> instances.
List of callbacks to apply during training.</p>
</td>
<td><code>None</code></td>
</tr>
<tr>
<td><code>validation_split</code></td>
<td><code>float</code></td>
<td>
<p>Float between 0 and 1.
Fraction of the training data to be used as validation data.
The model will set apart this fraction of the training data,
will not train on it, and will evaluate
the loss and any model metrics
on this data at the end of each epoch.
The validation data is selected from the last samples
in the <code>x</code> and <code>y</code> data provided, before shuffling. This argument is
not supported when <code>x</code> is a generator.</p>
</td>
<td><code>0.0</code></td>
</tr>
<tr>
<td><code>validation_data</code></td>
<td><code>Optional[Union[Tuple, Iterable]]</code></td>
<td>
<p>Data on which to evaluate
the loss and any model metrics at the end of each epoch.
The model will not be trained on this data.
<code>validation_data</code> will override <code>validation_split</code>.
<code>validation_data</code> could be:</p>
<ul>
<li>tuple <code>(x_val, y_val)</code> of Numpy/Jax arrays, list of arrays or mappings</li>
<li>tuple <code>(x_val, y_val, val_sample_weights)</code> of Numpy/Jax arrays, list
of arrays or mappings</li>
<li>generator</li>
</ul>
<p>For the first two cases, <code>batch_size</code> must be provided.
For the last case, <code>validation_steps</code> should be provided, and should
follow the same convention for yielding data as <code>x</code>.
Note that <code>validation_data</code> does not support all the data types that
are supported in <code>x</code>, eg, dict.</p>
</td>
<td><code>None</code></td>
</tr>
<tr>
<td><code>shuffle</code></td>
<td><code>bool</code></td>
<td>
<p>Boolean (whether to shuffle the training data
before each epoch). This argument is ignored
when <code>x</code> is a generator. Has no effect when <code>steps_per_epoch</code> is not <code>None</code>.</p>
</td>
<td><code>True</code></td>
</tr>
<tr>
<td><code>class_weight</code></td>
<td><code>Optional[Mapping[str, float]]</code></td>
<td>
<p>Optional dictionary mapping class indices (integers)
to a weight (float) value, used for weighting the loss function
(during training only).
This can be useful to tell the model to
"pay more attention" to samples from
an under-represented class.</p>
</td>
<td><code>None</code></td>
</tr>
<tr>
<td><code>sample_weight</code></td>
<td><code>Optional[numpy.ndarray]</code></td>
<td>
<p>Optional Numpy/Jax array of weights for
the training samples, used for weighting the loss function
(during training only). You can either pass a flat (1D)
Numpy array with the same length as the input samples
(1:1 mapping between weights and samples). This argument is not
supported when <code>x</code> is generator, instead provide the sample_weights
as the third element of <code>x</code>.</p>
</td>
<td><code>None</code></td>
</tr>
<tr>
<td><code>initial_epoch</code></td>
<td><code>int</code></td>
<td>
<p>Integer.
Epoch at which to start training
(useful for resuming a previous training run).</p>
</td>
<td><code>0</code></td>
</tr>
<tr>
<td><code>steps_per_epoch</code></td>
<td><code>Optional[int]</code></td>
<td>
<p>Integer or <code>None</code>.
Total number of steps (batches of samples)
before declaring one epoch finished and starting the
next epoch. When training with input arrays such as
jax data arrays, the default <code>None</code> is equal to
the number of samples in your dataset divided by
the batch size, or 1 if that cannot be determined.
When passing a generator, you must specify the
<code>steps_per_epoch</code> argument. This argument is not supported with
array inputs.</p>
</td>
<td><code>None</code></td>
</tr>
<tr>
<td><code>validation_steps</code></td>
<td><code>Optional[int]</code></td>
<td>
<p>Only relevant if <code>validation_data</code> is provided and
is a generator. Total number of steps (batches of
samples) to draw before stopping when performing validation
at the end of every epoch. If 'validation_steps' is None, validation
will run until the <code>validation_data</code> dataset is exhausted. In the
case of an infinitely repeated dataset, it will run into an
infinite loop. If 'validation_steps' is specified and only part of
the dataset will be consumed, the evaluation will start from the
beginning of the dataset at each epoch. This ensures that the same
validation samples are used every time.</p>
</td>
<td><code>None</code></td>
</tr>
<tr>
<td><code>validation_batch_size</code></td>
<td><code>Optional[int]</code></td>
<td>
<p>Integer or <code>None</code>.
Number of samples per validation batch.
If unspecified, will default to <code>batch_size</code>.
Do not specify the <code>validation_batch_size</code> if your data is in the
form of generators (since they generate batches).</p>
</td>
<td><code>None</code></td>
</tr>
<tr>
<td><code>validation_freq</code></td>
<td><code>int</code></td>
<td>
<p>Only relevant if validation data is provided. Integer
or <code>collections_abc.Container</code> instance (e.g. list, tuple, etc.).
If an integer, specifies how many training epochs to run before a
new validation run is performed, e.g. <code>validation_freq=2</code> runs
validation every 2 epochs. If a Container, specifies the epochs on
which to run validation, e.g. <code>validation_freq=[1, 2, 10]</code> runs
validation at the end of the 1st, 2nd, and 10th epochs.</p>
</td>
<td><code>1</code></td>
</tr>
</tbody>
</table>
<p>Unpacking behavior for iterator-like inputs:</p>
<p>A common pattern is to pass a generator, which will in fact
yield not only features (x) but optionally targets (y) and sample weights.
Elegy requires that the output of such iterator-likes be unambiguous. The
iterator should return a tuple of length 1, 2, or 3, where the optional
second and third elements will be used for y and sample_weight
respectively. Any other type provided will be wrapped in a length one
tuple, effectively treating everything as 'x'. When yielding dicts, they
should still adhere to the top-level tuple structure.
e.g. <code>({"x0": x0, "x1": x1}, y)</code>. Elegy will not attempt to separate
features, targets, and weights from the keys of a single dict.</p>
<p>A notable unsupported data type is the namedtuple. The reason is that
it behaves like both an ordered datatype (tuple) and a mapping
datatype (dict). So given a namedtuple of the form:
    <code>namedtuple("example_tuple", ["y", "x"])</code>
it is ambiguous whether to reverse the order of the elements when
interpreting the value. Even worse is a tuple of the form:
    <code>namedtuple("other_tuple", ["x", "y", "z"])</code>
where it is unclear if the tuple was intended to be unpacked into x, y,
and sample_weight or passed through as a single element to <code>x</code>. As a
result the data processing code will simply raise a ValueError if it
encounters a namedtuple. (Along with instructions to remedy the issue.)</p>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>History</code></td>
<td>
<p>A <code>History</code> object. Its <code>History.history</code> attribute is
a record of training loss values and metrics values
at successive epochs, as well as validation loss values
and validation metrics values (if applicable).</p>
</td>
</tr>
</tbody>
</table>
<p><strong>Exceptions:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>ValueError</code></td>
<td>
<p>In case of mismatch between the provided input data
and what the model expects.</p>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>elegy/model.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>462
463
464
465
466
467
468
469
470
471
472
473
474
475
476
477
478
479
480
481
482
483
484
485
486
487
488
489
490
491
492
493
494
495
496
497
498
499
500
501
502
503
504
505
506
507
508
509
510
511
512
513
514
515
516
517
518
519
520
521
522
523
524
525
526
527
528
529
530
531
532
533
534
535
536
537
538
539
540
541
542
543
544
545
546
547
548
549
550
551
552
553
554
555
556
557
558
559
560
561
562
563
564
565
566
567
568
569
570
571
572
573
574
575
576
577
578
579
580
581
582
583
584
585
586
587
588
589
590
591
592
593
594
595
596
597
598
599
600
601
602
603
604
605
606
607
608
609
610
611
612
613
614
615
616
617
618
619
620
621
622
623
624
625
626
627
628
629
630
631
632
633
634
635
636
637
638
639
640
641
642
643
644
645
646
647
648
649
650
651
652
653
654
655
656
657
658
659
660
661
662
663
664
665
666
667
668
669
670
671
672
673
674
675
676
677
678
679
680
681
682
683
684
685
686
687
688
689
690
691
692
693
694
695
696
697
698
699
700
701
702
703
704
705
706
707
708
709
710
711
712
713
714
715
716
717
718
719
720
721
722
723</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">fit</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">tp</span><span class="o">.</span><span class="n">Union</span><span class="p">[</span>
        <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">tp</span><span class="o">.</span><span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span> <span class="n">tp</span><span class="o">.</span><span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span> <span class="n">tp</span><span class="o">.</span><span class="n">Iterable</span><span class="p">,</span>
    <span class="p">],</span>
    <span class="n">y</span><span class="p">:</span> <span class="n">tp</span><span class="o">.</span><span class="n">Union</span><span class="p">[</span>
        <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">tp</span><span class="o">.</span><span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span> <span class="n">tp</span><span class="o">.</span><span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="p">:</span> <span class="n">tp</span><span class="o">.</span><span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">epochs</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">verbose</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">callbacks</span><span class="p">:</span> <span class="n">tp</span><span class="o">.</span><span class="n">Union</span><span class="p">[</span><span class="n">tp</span><span class="o">.</span><span class="n">List</span><span class="p">[</span><span class="n">Callback</span><span class="p">],</span> <span class="n">CallbackList</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">validation_split</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
    <span class="n">validation_data</span><span class="p">:</span> <span class="n">tp</span><span class="o">.</span><span class="n">Union</span><span class="p">[</span><span class="n">tp</span><span class="o">.</span><span class="n">Tuple</span><span class="p">,</span> <span class="n">tp</span><span class="o">.</span><span class="n">Iterable</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">class_weight</span><span class="p">:</span> <span class="n">tp</span><span class="o">.</span><span class="n">Optional</span><span class="p">[</span><span class="n">tp</span><span class="o">.</span><span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">sample_weight</span><span class="p">:</span> <span class="n">tp</span><span class="o">.</span><span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">initial_epoch</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
    <span class="n">steps_per_epoch</span><span class="p">:</span> <span class="n">tp</span><span class="o">.</span><span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">validation_steps</span><span class="p">:</span> <span class="n">tp</span><span class="o">.</span><span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">validation_batch_size</span><span class="p">:</span> <span class="n">tp</span><span class="o">.</span><span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">validation_freq</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">History</span><span class="p">:</span>
    <span class="sd">"""</span>
<span class="sd">    Trains the model for a fixed number of epochs (iterations on a dataset).</span>

<span class="sd">    Arguments:</span>
<span class="sd">        x: Input data. It could be:</span>

<span class="sd">            - A Numpy or Jax array (or array-like), or a list of arrays</span>
<span class="sd">                (in case the model has multiple inputs).</span>
<span class="sd">            - A dict mapping input names to the corresponding arrays,</span>
<span class="sd">                if the model has named inputs.</span>
<span class="sd">            - A generator returning `(inputs,)`, `(inputs, targets)`</span>
<span class="sd">                or `(inputs, targets, sample_weights)`.</span>

<span class="sd">            A more detailed description of unpacking behavior for generator type</span>
<span class="sd">            is given below.</span>
<span class="sd">        y: Target data. Like the input data `x`,</span>
<span class="sd">            it could be either Numpy or Jax array(s).</span>
<span class="sd">            It should be consistent with `x`. If `x` is a generator,</span>
<span class="sd">            `y` should not be specified (since targets will be obtained from `x`).</span>
<span class="sd">        batch_size: Integer or `None`.</span>
<span class="sd">            Number of samples per gradient update.</span>
<span class="sd">            If unspecified, `batch_size` will default to 32.</span>
<span class="sd">            Do not specify the `batch_size` if your data is in the</span>
<span class="sd">            form of generator (since they generate batches).</span>
<span class="sd">        epochs: Integer. Number of epochs to train the model.</span>
<span class="sd">            An epoch is an iteration over the entire `x` and `y`</span>
<span class="sd">            data provided.</span>
<span class="sd">            Note that in conjunction with `initial_epoch`,</span>
<span class="sd">            `epochs` is to be understood as "final epoch".</span>
<span class="sd">            The model is not trained for a number of iterations</span>
<span class="sd">            given by `epochs`, but merely until the epoch</span>
<span class="sd">            of index `epochs` is reached.</span>
<span class="sd">        verbose: 0, 1, or 2. Verbosity mode.</span>
<span class="sd">            0 = silent, 1 = progress bar, 2 = one line per epoch.</span>
<span class="sd">            Note that the progress bar is not particularly useful when</span>
<span class="sd">            logged to a file, so verbose=2 is recommended when not running</span>
<span class="sd">            interactively (eg, in a production environment).</span>
<span class="sd">        callbacks: List of [elegy.callbacks.callback.Callback][] instances.</span>
<span class="sd">            List of callbacks to apply during training.</span>
<span class="sd">        validation_split: Float between 0 and 1.</span>
<span class="sd">            Fraction of the training data to be used as validation data.</span>
<span class="sd">            The model will set apart this fraction of the training data,</span>
<span class="sd">            will not train on it, and will evaluate</span>
<span class="sd">            the loss and any model metrics</span>
<span class="sd">            on this data at the end of each epoch.</span>
<span class="sd">            The validation data is selected from the last samples</span>
<span class="sd">            in the `x` and `y` data provided, before shuffling. This argument is</span>
<span class="sd">            not supported when `x` is a generator.</span>
<span class="sd">        validation_data: Data on which to evaluate</span>
<span class="sd">            the loss and any model metrics at the end of each epoch.</span>
<span class="sd">            The model will not be trained on this data.</span>
<span class="sd">            `validation_data` will override `validation_split`.</span>
<span class="sd">            `validation_data` could be:</span>

<span class="sd">            - tuple `(x_val, y_val)` of Numpy/Jax arrays, list of arrays or mappings</span>
<span class="sd">            - tuple `(x_val, y_val, val_sample_weights)` of Numpy/Jax arrays, list</span>
<span class="sd">            of arrays or mappings</span>
<span class="sd">            - generator</span>

<span class="sd">            For the first two cases, `batch_size` must be provided.</span>
<span class="sd">            For the last case, `validation_steps` should be provided, and should</span>
<span class="sd">            follow the same convention for yielding data as `x`.</span>
<span class="sd">            Note that `validation_data` does not support all the data types that</span>
<span class="sd">            are supported in `x`, eg, dict.</span>
<span class="sd">        shuffle: Boolean (whether to shuffle the training data</span>
<span class="sd">            before each epoch). This argument is ignored</span>
<span class="sd">            when `x` is a generator. Has no effect when `steps_per_epoch` is not `None`.</span>
<span class="sd">        class_weight: Optional dictionary mapping class indices (integers)</span>
<span class="sd">            to a weight (float) value, used for weighting the loss function</span>
<span class="sd">            (during training only).</span>
<span class="sd">            This can be useful to tell the model to</span>
<span class="sd">            "pay more attention" to samples from</span>
<span class="sd">            an under-represented class.</span>
<span class="sd">        sample_weight: Optional Numpy/Jax array of weights for</span>
<span class="sd">            the training samples, used for weighting the loss function</span>
<span class="sd">            (during training only). You can either pass a flat (1D)</span>
<span class="sd">            Numpy array with the same length as the input samples</span>
<span class="sd">            (1:1 mapping between weights and samples). This argument is not</span>
<span class="sd">            supported when `x` is generator, instead provide the sample_weights</span>
<span class="sd">            as the third element of `x`.</span>
<span class="sd">        initial_epoch: Integer.</span>
<span class="sd">            Epoch at which to start training</span>
<span class="sd">            (useful for resuming a previous training run).</span>
<span class="sd">        steps_per_epoch: Integer or `None`.</span>
<span class="sd">            Total number of steps (batches of samples)</span>
<span class="sd">            before declaring one epoch finished and starting the</span>
<span class="sd">            next epoch. When training with input arrays such as</span>
<span class="sd">            jax data arrays, the default `None` is equal to</span>
<span class="sd">            the number of samples in your dataset divided by</span>
<span class="sd">            the batch size, or 1 if that cannot be determined.</span>
<span class="sd">            When passing a generator, you must specify the</span>
<span class="sd">            `steps_per_epoch` argument. This argument is not supported with</span>
<span class="sd">            array inputs.</span>
<span class="sd">        validation_steps: Only relevant if `validation_data` is provided and</span>
<span class="sd">            is a generator. Total number of steps (batches of</span>
<span class="sd">            samples) to draw before stopping when performing validation</span>
<span class="sd">            at the end of every epoch. If 'validation_steps' is None, validation</span>
<span class="sd">            will run until the `validation_data` dataset is exhausted. In the</span>
<span class="sd">            case of an infinitely repeated dataset, it will run into an</span>
<span class="sd">            infinite loop. If 'validation_steps' is specified and only part of</span>
<span class="sd">            the dataset will be consumed, the evaluation will start from the</span>
<span class="sd">            beginning of the dataset at each epoch. This ensures that the same</span>
<span class="sd">            validation samples are used every time.</span>
<span class="sd">        validation_batch_size: Integer or `None`.</span>
<span class="sd">            Number of samples per validation batch.</span>
<span class="sd">            If unspecified, will default to `batch_size`.</span>
<span class="sd">            Do not specify the `validation_batch_size` if your data is in the</span>
<span class="sd">            form of generators (since they generate batches).</span>
<span class="sd">        validation_freq: Only relevant if validation data is provided. Integer</span>
<span class="sd">            or `collections_abc.Container` instance (e.g. list, tuple, etc.).</span>
<span class="sd">            If an integer, specifies how many training epochs to run before a</span>
<span class="sd">            new validation run is performed, e.g. `validation_freq=2` runs</span>
<span class="sd">            validation every 2 epochs. If a Container, specifies the epochs on</span>
<span class="sd">            which to run validation, e.g. `validation_freq=[1, 2, 10]` runs</span>
<span class="sd">            validation at the end of the 1st, 2nd, and 10th epochs.</span>

<span class="sd">    Unpacking behavior for iterator-like inputs:</span>

<span class="sd">    A common pattern is to pass a generator, which will in fact</span>
<span class="sd">    yield not only features (x) but optionally targets (y) and sample weights.</span>
<span class="sd">    Elegy requires that the output of such iterator-likes be unambiguous. The</span>
<span class="sd">    iterator should return a tuple of length 1, 2, or 3, where the optional</span>
<span class="sd">    second and third elements will be used for y and sample_weight</span>
<span class="sd">    respectively. Any other type provided will be wrapped in a length one</span>
<span class="sd">    tuple, effectively treating everything as 'x'. When yielding dicts, they</span>
<span class="sd">    should still adhere to the top-level tuple structure.</span>
<span class="sd">    e.g. `({"x0": x0, "x1": x1}, y)`. Elegy will not attempt to separate</span>
<span class="sd">    features, targets, and weights from the keys of a single dict.</span>

<span class="sd">    A notable unsupported data type is the namedtuple. The reason is that</span>
<span class="sd">    it behaves like both an ordered datatype (tuple) and a mapping</span>
<span class="sd">    datatype (dict). So given a namedtuple of the form:</span>
<span class="sd">        `namedtuple("example_tuple", ["y", "x"])`</span>
<span class="sd">    it is ambiguous whether to reverse the order of the elements when</span>
<span class="sd">    interpreting the value. Even worse is a tuple of the form:</span>
<span class="sd">        `namedtuple("other_tuple", ["x", "y", "z"])`</span>
<span class="sd">    where it is unclear if the tuple was intended to be unpacked into x, y,</span>
<span class="sd">    and sample_weight or passed through as a single element to `x`. As a</span>
<span class="sd">    result the data processing code will simply raise a ValueError if it</span>
<span class="sd">    encounters a namedtuple. (Along with instructions to remedy the issue.)</span>

<span class="sd">    Returns:</span>
<span class="sd">        A `History` object. Its `History.history` attribute is</span>
<span class="sd">        a record of training loss values and metrics values</span>
<span class="sd">        at successive epochs, as well as validation loss values</span>
<span class="sd">        and validation metrics values (if applicable).</span>
<span class="sd">    Raises:</span>
<span class="sd">        ValueError: In case of mismatch between the provided input data</span>
<span class="sd">            and what the model expects.</span>
<span class="sd">    """</span>
    <span class="k">if</span> <span class="n">validation_split</span><span class="p">:</span>
        <span class="c1"># Create the validation data using the training data. Only supported for</span>
        <span class="c1"># `Jax Numpy` and `NumPy` input.</span>
        <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">sample_weight</span><span class="p">),</span> <span class="n">validation_data</span> <span class="o">=</span> <span class="n">train_validation_split</span><span class="p">(</span>
            <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">sample_weight</span><span class="p">),</span> <span class="n">validation_split</span><span class="o">=</span><span class="n">validation_split</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span>
        <span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">stop_training</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">data_handler</span> <span class="o">=</span> <span class="n">DataHandler</span><span class="p">(</span>
        <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span>
        <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span>
        <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
        <span class="n">steps_per_epoch</span><span class="o">=</span><span class="n">steps_per_epoch</span><span class="p">,</span>
        <span class="n">initial_epoch</span><span class="o">=</span><span class="n">initial_epoch</span><span class="p">,</span>
        <span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">,</span>
        <span class="n">shuffle</span><span class="o">=</span><span class="n">shuffle</span><span class="p">,</span>
        <span class="n">class_weight</span><span class="o">=</span><span class="n">class_weight</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="c1"># Container that configures and calls `tf.keras.Callback`s.</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">callbacks</span><span class="p">,</span> <span class="n">CallbackList</span><span class="p">):</span>
        <span class="n">callbacks</span> <span class="o">=</span> <span class="n">CallbackList</span><span class="p">(</span>
            <span class="n">callbacks</span><span class="p">,</span>
            <span class="n">add_history</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">add_progbar</span><span class="o">=</span><span class="n">verbose</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">,</span>
            <span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="p">,</span>
            <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>
            <span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">,</span>
            <span class="n">steps</span><span class="o">=</span><span class="n">data_handler</span><span class="o">.</span><span class="n">inferred_steps</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="n">callbacks</span><span class="o">.</span><span class="n">on_train_begin</span><span class="p">()</span>
    <span class="c1"># data_handler._initial_epoch = (  # pylint: disable=protected-access</span>
    <span class="c1">#     self._maybe_load_initial_epoch_from_ckpt(initial_epoch))</span>

    <span class="k">for</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">iterator</span> <span class="ow">in</span> <span class="n">data_handler</span><span class="o">.</span><span class="n">enumerate_epochs</span><span class="p">():</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reset_metrics</span><span class="p">()</span>
        <span class="n">callbacks</span><span class="o">.</span><span class="n">on_epoch_begin</span><span class="p">(</span><span class="n">epoch</span><span class="p">)</span>
        <span class="n">logs</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">with</span> <span class="n">data_handler</span><span class="o">.</span><span class="n">catch_stop_iteration</span><span class="p">():</span>
            <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="n">data_handler</span><span class="o">.</span><span class="n">steps</span><span class="p">():</span>
                <span class="n">callbacks</span><span class="o">.</span><span class="n">on_train_batch_begin</span><span class="p">(</span><span class="n">step</span><span class="p">)</span>
                <span class="n">batch</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span>
                <span class="c1"># sample_weight = batch[2] if len(batch) == 3 else None</span>
                <span class="n">x_batch</span><span class="p">,</span> <span class="n">y_batch</span><span class="p">,</span> <span class="n">sample_weight</span> <span class="o">=</span> <span class="n">unpack_x_y_sample_weight</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>

                <span class="n">tmp_logs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_on_batch</span><span class="p">(</span>
                    <span class="n">x</span><span class="o">=</span><span class="n">x_batch</span><span class="p">,</span>
                    <span class="n">y</span><span class="o">=</span><span class="n">y_batch</span><span class="p">,</span>
                    <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">,</span>
                    <span class="n">class_weight</span><span class="o">=</span><span class="n">class_weight</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="n">tmp_logs</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s2">"size"</span><span class="p">:</span> <span class="n">data_handler</span><span class="o">.</span><span class="n">batch_size</span><span class="p">})</span>
                <span class="c1"># print(epoch, step, tmp_logs["accuracy"], batch[0].shape)</span>

                <span class="n">logs</span> <span class="o">=</span> <span class="n">tmp_logs</span>
                <span class="n">callbacks</span><span class="o">.</span><span class="n">on_train_batch_end</span><span class="p">(</span><span class="n">step</span><span class="p">,</span> <span class="n">logs</span><span class="p">)</span>

        <span class="n">epoch_logs</span> <span class="o">=</span> <span class="n">copy</span><span class="p">(</span><span class="n">logs</span><span class="p">)</span>
        <span class="n">epoch_logs</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s2">"size"</span><span class="p">:</span> <span class="n">data_handler</span><span class="o">.</span><span class="n">batch_size</span><span class="p">})</span>

        <span class="c1"># Run validation.</span>
        <span class="k">if</span> <span class="n">validation_data</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_should_eval</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">validation_freq</span><span class="p">):</span>
            <span class="n">val_x</span><span class="p">,</span> <span class="n">val_y</span><span class="p">,</span> <span class="n">val_sample_weight</span> <span class="o">=</span> <span class="n">unpack_x_y_sample_weight</span><span class="p">(</span>
                <span class="n">validation_data</span>
            <span class="p">)</span>
            <span class="n">val_logs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span>
                <span class="n">x</span><span class="o">=</span><span class="n">val_x</span><span class="p">,</span>
                <span class="n">y</span><span class="o">=</span><span class="n">val_y</span><span class="p">,</span>
                <span class="n">sample_weight</span><span class="o">=</span><span class="n">val_sample_weight</span><span class="p">,</span>
                <span class="n">batch_size</span><span class="o">=</span><span class="n">validation_batch_size</span> <span class="ow">or</span> <span class="n">batch_size</span><span class="p">,</span>
                <span class="n">steps</span><span class="o">=</span><span class="n">validation_steps</span><span class="p">,</span>
                <span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="p">,</span>
                <span class="c1"># return_dict=True,</span>
            <span class="p">)</span>
            <span class="n">val_logs</span> <span class="o">=</span> <span class="p">{</span><span class="s2">"val_"</span> <span class="o">+</span> <span class="n">name</span><span class="p">:</span> <span class="n">val</span> <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">val_logs</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
            <span class="n">epoch_logs</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">val_logs</span><span class="p">)</span>

        <span class="n">callbacks</span><span class="o">.</span><span class="n">on_epoch_end</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">epoch_logs</span><span class="p">)</span>
        <span class="c1"># print(</span>
        <span class="c1">#     f"epoch: {epoch} - "</span>
        <span class="c1">#     + " - ".join(f"{key}: {value:.3f}" for key, value in epoch_logs.items())</span>
        <span class="c1"># )</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">stop_training</span><span class="p">:</span>
            <span class="k">break</span>

    <span class="n">callbacks</span><span class="o">.</span><span class="n">on_train_end</span><span class="p">()</span>

    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">history</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h2 class="doc doc-heading" id="elegy.model.Model.load">
<code class="highlight language-python">
load<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">)</span> </code>
</h2>
<div class="doc doc-contents">
<p>Loads all weights + states from a folder structure.</p>
<p>You can load states from other models that have slightly different architecture
as long as long as it preserves the ordering of the <code>haiku.Params</code> + <code>haiku.State</code> 
structures, adding or removing layers is fine as long as they don't have weights, 
new layers with weights will be initialized from scratch.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>path</code></td>
<td><code>Union[str, pathlib.Path]</code></td>
<td>
<p>path to a saved model's directory.</p>
</td>
<td><em>required</em></td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>elegy/model.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>1296
1297
1298
1299
1300
1301
1302
1303
1304
1305
1306
1307
1308
1309
1310
1311
1312
1313
1314
1315
1316
1317
1318
1319</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">load</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">:</span> <span class="n">tp</span><span class="o">.</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Path</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
    <span class="sd">"""</span>
<span class="sd">    Loads all weights + states from a folder structure.</span>

<span class="sd">    You can load states from other models that have slightly different architecture</span>
<span class="sd">    as long as long as it preserves the ordering of the `haiku.Params` + `haiku.State` </span>
<span class="sd">    structures, adding or removing layers is fine as long as they don't have weights, </span>
<span class="sd">    new layers with weights will be initialized from scratch.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        path: path to a saved model's directory.</span>
<span class="sd">    """</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
        <span class="n">path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>

    <span class="n">state</span><span class="p">:</span> <span class="n">tp</span><span class="o">.</span><span class="n">Dict</span> <span class="o">=</span> <span class="n">deepdish</span><span class="o">.</span><span class="n">io</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">path</span> <span class="o">/</span> <span class="s2">"parameters.h5"</span><span class="p">)</span>

    <span class="n">optimizer_state_path</span> <span class="o">=</span> <span class="n">path</span> <span class="o">/</span> <span class="s2">"optimizer_state.pkl"</span>

    <span class="k">if</span> <span class="n">optimizer_state_path</span><span class="o">.</span><span class="n">exists</span><span class="p">():</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">optimizer_state_path</span><span class="p">,</span> <span class="s2">"rb"</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="n">state</span><span class="p">[</span><span class="s2">"optimizer_state"</span><span class="p">]</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">full_state</span> <span class="o">=</span> <span class="n">state</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h2 class="doc doc-heading" id="elegy.model.Model.predict">
<code class="highlight language-python">
predict<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">steps</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> </code>
</h2>
<div class="doc doc-contents">
<p>Generates output predictions for the input samples.
Computation is done in batches.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>x</code></td>
<td><code>Union[numpy.ndarray, Mapping[str, numpy.ndarray], Tuple[numpy.ndarray], Iterable]</code></td>
<td>
<p>Input data. It could be:</p>
<ul>
<li>A Numpy or Jax array (or array-like), or a list of arrays
    (in case the model has multiple inputs).</li>
<li>A dict mapping input names to the corresponding arrays,
    if the model has named inputs.</li>
<li>A generator returning <code>(inputs,)</code>, <code>(inputs, targets)</code>
    or <code>(inputs, targets, sample_weights)</code>.</li>
</ul>
<p>A more detailed description of
unpacking behavior for iterator types generator
is given in the <code>Unpacking behavior for iterator-like inputs</code> section
of <code>Model.fit</code>.</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>batch_size</code></td>
<td><code>Optional[int]</code></td>
<td>
<p>Integer or <code>None</code>.
Number of samples per batch.
If unspecified, <code>batch_size</code> will default to 32.
Do not specify the <code>batch_size</code> if your data is in the
form of generators (since they generate batches).</p>
</td>
<td><code>None</code></td>
</tr>
<tr>
<td><code>verbose</code></td>
<td><code>int</code></td>
<td>
<p>Verbosity mode, 0 or 1.</p>
</td>
<td><code>0</code></td>
</tr>
<tr>
<td><code>steps</code></td>
<td><code>Optional[int]</code></td>
<td>
<p>Total number of steps (batches of samples)
before declaring the prediction round finished.
Ignored with the default value of <code>None</code>.</p>
</td>
<td><code>None</code></td>
</tr>
<tr>
<td><code>callbacks</code></td>
<td><code>Optional[Union[List[elegy.callbacks.callback.Callback], elegy.callbacks.callback_list.CallbackList]]</code></td>
<td>
<p>List of <a href="https://poets-ai.github.io/elegy/api/callbacks/Callback/#elegy.callbacks.callback.Callback">elegy.callbacks.callback.Callback</a> instances.
List of callbacks to apply during training.</p>
</td>
<td><code>None</code></td>
</tr>
</tbody>
</table>
<p>See the discussion of <code>Unpacking behavior for iterator-like inputs</code> for
<a href="https://poets-ai.github.io/elegy/api/model/Model/#elegy.model.Model.fit"><code>Model.fit</code></a>.
Note that Model.predict uses the same interpretation rules as
<code>Model.fit</code> and <code>Model.evaluate</code>, so inputs must be unambiguous for all
three methods.</p>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>ndarray</code></td>
<td>
<p>Numpy array(s) of predictions.</p>
</td>
</tr>
</tbody>
</table>
<p><strong>Exceptions:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>ValueError</code></td>
<td>
<p>In case of mismatch between the provided
input data and the model's expectations,
or in case a stateful model receives a number of samples
that is not a multiple of the batch size.</p>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>elegy/model.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>840
841
842
843
844
845
846
847
848
849
850
851
852
853
854
855
856
857
858
859
860
861
862
863
864
865
866
867
868
869
870
871
872
873
874
875
876
877
878
879
880
881
882
883
884
885
886
887
888
889
890
891
892
893
894
895
896
897
898
899
900
901
902
903
904
905
906
907
908
909
910
911
912
913
914
915
916
917
918
919
920
921
922
923
924
925
926
927
928
929
930
931
932
933
934
935
936
937
938
939
940
941
942
943
944</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">predict</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">tp</span><span class="o">.</span><span class="n">Union</span><span class="p">[</span>
        <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">tp</span><span class="o">.</span><span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span> <span class="n">tp</span><span class="o">.</span><span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span> <span class="n">tp</span><span class="o">.</span><span class="n">Iterable</span><span class="p">,</span>
    <span class="p">],</span>
    <span class="n">verbose</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="p">:</span> <span class="n">tp</span><span class="o">.</span><span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">steps</span><span class="p">:</span> <span class="n">tp</span><span class="o">.</span><span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">callbacks</span><span class="p">:</span> <span class="n">tp</span><span class="o">.</span><span class="n">Union</span><span class="p">[</span><span class="n">tp</span><span class="o">.</span><span class="n">List</span><span class="p">[</span><span class="n">Callback</span><span class="p">],</span> <span class="n">CallbackList</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
    <span class="sd">"""Generates output predictions for the input samples.</span>
<span class="sd">    Computation is done in batches.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        x: Input data. It could be:</span>

<span class="sd">            - A Numpy or Jax array (or array-like), or a list of arrays</span>
<span class="sd">                (in case the model has multiple inputs).</span>
<span class="sd">            - A dict mapping input names to the corresponding arrays,</span>
<span class="sd">                if the model has named inputs.</span>
<span class="sd">            - A generator returning `(inputs,)`, `(inputs, targets)`</span>
<span class="sd">                or `(inputs, targets, sample_weights)`.</span>

<span class="sd">            A more detailed description of</span>
<span class="sd">            unpacking behavior for iterator types generator</span>
<span class="sd">            is given in the `Unpacking behavior for iterator-like inputs` section</span>
<span class="sd">            of `Model.fit`.</span>
<span class="sd">        batch_size: Integer or `None`.</span>
<span class="sd">            Number of samples per batch.</span>
<span class="sd">            If unspecified, `batch_size` will default to 32.</span>
<span class="sd">            Do not specify the `batch_size` if your data is in the</span>
<span class="sd">            form of generators (since they generate batches).</span>
<span class="sd">        verbose: Verbosity mode, 0 or 1.</span>
<span class="sd">        steps: Total number of steps (batches of samples)</span>
<span class="sd">            before declaring the prediction round finished.</span>
<span class="sd">            Ignored with the default value of `None`.</span>
<span class="sd">        callbacks: List of [elegy.callbacks.callback.Callback][] instances.</span>
<span class="sd">            List of callbacks to apply during training.</span>

<span class="sd">    See the discussion of `Unpacking behavior for iterator-like inputs` for</span>
<span class="sd">    [`Model.fit`][elegy.model.Model.fit].</span>
<span class="sd">    Note that Model.predict uses the same interpretation rules as</span>
<span class="sd">    `Model.fit` and `Model.evaluate`, so inputs must be unambiguous for all</span>
<span class="sd">    three methods.</span>
<span class="sd">    Returns:</span>
<span class="sd">        Numpy array(s) of predictions.</span>
<span class="sd">    Raises:</span>
<span class="sd">        ValueError: In case of mismatch between the provided</span>
<span class="sd">            input data and the model's expectations,</span>
<span class="sd">            or in case a stateful model receives a number of samples</span>
<span class="sd">            that is not a multiple of the batch size.</span>
<span class="sd">    """</span>

    <span class="n">outputs</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="n">data_handler</span> <span class="o">=</span> <span class="n">DataHandler</span><span class="p">(</span>
        <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
        <span class="n">steps_per_epoch</span><span class="o">=</span><span class="n">steps</span><span class="p">,</span>
        <span class="n">initial_epoch</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="c1"># Container that configures and calls `tf.keras.Callback`s.</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">callbacks</span><span class="p">,</span> <span class="n">CallbackList</span><span class="p">):</span>
        <span class="n">callbacks</span> <span class="o">=</span> <span class="n">CallbackList</span><span class="p">(</span>
            <span class="n">callbacks</span><span class="p">,</span>
            <span class="n">add_history</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">add_progbar</span><span class="o">=</span><span class="n">verbose</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">,</span>
            <span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="p">,</span>
            <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>
            <span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
            <span class="n">steps</span><span class="o">=</span><span class="n">data_handler</span><span class="o">.</span><span class="n">inferred_steps</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="n">callbacks</span><span class="o">.</span><span class="n">on_predict_begin</span><span class="p">()</span>

    <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">iterator</span> <span class="ow">in</span> <span class="n">data_handler</span><span class="o">.</span><span class="n">enumerate_epochs</span><span class="p">():</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reset_metrics</span><span class="p">()</span>
        <span class="k">with</span> <span class="n">data_handler</span><span class="o">.</span><span class="n">catch_stop_iteration</span><span class="p">():</span>
            <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="n">data_handler</span><span class="o">.</span><span class="n">steps</span><span class="p">():</span>
                <span class="n">callbacks</span><span class="o">.</span><span class="n">on_predict_batch_begin</span><span class="p">(</span><span class="n">step</span><span class="p">)</span>
                <span class="n">batch</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span>
                <span class="n">tmp_batch_outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict_on_batch</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">batch</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
                <span class="n">batch_outputs</span> <span class="o">=</span> <span class="n">tmp_batch_outputs</span>

                <span class="k">if</span> <span class="n">outputs</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">outputs</span> <span class="o">=</span> <span class="n">map_structure</span><span class="p">(</span>
                        <span class="k">lambda</span> <span class="n">batch_output</span><span class="p">:</span> <span class="p">[</span><span class="n">batch_output</span><span class="p">],</span> <span class="n">batch_outputs</span>
                    <span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>

                    <span class="n">outputs</span> <span class="o">=</span> <span class="n">map_structure</span><span class="p">(</span><span class="n">map_append</span><span class="p">,</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">batch_outputs</span><span class="p">,)</span>

                <span class="n">callbacks</span><span class="o">.</span><span class="n">on_predict_batch_end</span><span class="p">(</span>
                    <span class="n">step</span><span class="p">,</span>
                    <span class="p">{</span><span class="s2">"outputs"</span><span class="p">:</span> <span class="n">batch_outputs</span><span class="p">,</span> <span class="s2">"size"</span><span class="p">:</span> <span class="n">data_handler</span><span class="o">.</span><span class="n">batch_size</span><span class="p">},</span>
                <span class="p">)</span>

    <span class="n">callbacks</span><span class="o">.</span><span class="n">on_predict_end</span><span class="p">()</span>

    <span class="n">all_outputs</span> <span class="o">=</span> <span class="n">map_structure</span><span class="p">(</span><span class="n">jnp</span><span class="o">.</span><span class="n">concatenate</span><span class="p">,</span> <span class="n">outputs</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">all_outputs</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h2 class="doc doc-heading" id="elegy.model.Model.predict_on_batch">
<code class="highlight language-python">
predict_on_batch<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span> </code>
</h2>
<div class="doc doc-contents">
<p>Returns predictions for a single batch of samples.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>x</code></td>
<td><code>Union[jax.numpy.lax_numpy.ndarray, Mapping[str, Any], Tuple]</code></td>
<td>
<p>Input data. A Numpy/Jax array (or array-like), or possibly 
nested python structure of dict, list, tuple that contain 
arrays as leafs.</p>
</td>
<td><em>required</em></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>Union[jax.numpy.lax_numpy.ndarray, Mapping[str, Any], Tuple]</code></td>
<td>
<p>Jax array(s) of predictions.</p>
</td>
</tr>
</tbody>
</table>
<p><strong>Exceptions:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>ValueError</code></td>
<td>
<p>In case of mismatch between given number of inputs and
expectations of the model.</p>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>elegy/model.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>1090
1091
1092
1093
1094
1095
1096
1097
1098
1099
1100
1101
1102
1103
1104
1105
1106
1107
1108
1109
1110
1111
1112
1113
1114
1115
1116
1117
1118
1119
1120
1121</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">predict_on_batch</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">tp</span><span class="o">.</span><span class="n">Union</span><span class="p">[</span><span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">tp</span><span class="o">.</span><span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">tp</span><span class="o">.</span><span class="n">Any</span><span class="p">],</span> <span class="n">tp</span><span class="o">.</span><span class="n">Tuple</span><span class="p">]</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">tp</span><span class="o">.</span><span class="n">Union</span><span class="p">[</span><span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">tp</span><span class="o">.</span><span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">tp</span><span class="o">.</span><span class="n">Any</span><span class="p">],</span> <span class="n">tp</span><span class="o">.</span><span class="n">Tuple</span><span class="p">]:</span>
    <span class="sd">"""</span>
<span class="sd">    Returns predictions for a single batch of samples.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        x: Input data. A Numpy/Jax array (or array-like), or possibly </span>
<span class="sd">            nested python structure of dict, list, tuple that contain </span>
<span class="sd">            arrays as leafs.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Jax array(s) of predictions.</span>

<span class="sd">    Raises:</span>
<span class="sd">        ValueError: In case of mismatch between given number of inputs and</span>
<span class="sd">            expectations of the model.</span>
<span class="sd">    """</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_maybe_initialize</span><span class="p">(</span>
        <span class="n">mode</span><span class="o">=</span><span class="n">Mode</span><span class="o">.</span><span class="n">predict</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">class_weight</span><span class="o">=</span><span class="kc">None</span>
    <span class="p">)</span>

    <span class="n">transformed_state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_predict</span><span class="p">(</span>
        <span class="kc">False</span><span class="p">,</span>  <span class="c1"># is_training</span>
        <span class="kc">False</span><span class="p">,</span>  <span class="c1"># get_summaries</span>
        <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span>
        <span class="n">params</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">,</span>
        <span class="n">state</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="p">,</span>
        <span class="n">net_rng</span><span class="o">=</span><span class="nb">next</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_rngs</span><span class="p">),</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">transformed_state</span><span class="o">.</span><span class="n">outputs</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h2 class="doc doc-heading" id="elegy.model.Model.save">
<code class="highlight language-python">
save<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">,</span> <span class="n">include_optimizer</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> </code>
</h2>
<div class="doc doc-contents">
<p>Saves the model to disk.</p>
<p>It creates a directory that includes:</p>
<ul>
<li>The <code>Model</code> object instance serialized with <code>pickle</code> as
    as <code>{path}/model.pkl</code>, this allows you to re-instantiate 
    the model later.</li>
<li>The model parameters + states serialized into HDF5 as <code>{path}/parameters.h5</code>.</li>
<li>The state of the optimizer serialized with <code>pickle</code> as
    as <code>{path}/optimizer_state.pkl</code>, allowing to resume training
    exactly where you left off. We hope to use HDF5 in the future
    but <code>optix</code> state is incompatible with <code>deepdish</code>.</li>
</ul>
<p>This allows you to save the entirety of the state of a model
in a directory structure which can be fully restored via 
<code>Model.load</code> if the model is already instiated or <code>elegy.model.load</code>
to load the model instance from its pickled version.</p>
<div class="codehilite">
<pre><span></span><code><span class="kn">import</span> <span class="nn">elegy</span>

<span class="n">model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">'my_model'</span><span class="p">)</span>  <span class="c1"># creates folder at 'my_model'</span>
<span class="k">del</span> <span class="n">model</span>  <span class="c1"># deletes the existing model</span>

<span class="c1"># returns a model identical to the previous one</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">elegy</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">'my_model'</span><span class="p">)</span>
</code></pre>
</div>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>path</code></td>
<td><code>Union[str, pathlib.Path]</code></td>
<td>
<p>path where model structure will be saved.</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>include_optimizer</code></td>
<td><code>bool</code></td>
<td>
<p>If True, save optimizer's state together.</p>
</td>
<td><code>True</code></td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>elegy/model.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>1231
1232
1233
1234
1235
1236
1237
1238
1239
1240
1241
1242
1243
1244
1245
1246
1247
1248
1249
1250
1251
1252
1253
1254
1255
1256
1257
1258
1259
1260
1261
1262
1263
1264
1265
1266
1267
1268
1269
1270
1271
1272
1273
1274
1275
1276
1277
1278
1279
1280
1281
1282
1283
1284
1285
1286
1287
1288
1289
1290
1291
1292
1293
1294</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">save</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">:</span> <span class="n">tp</span><span class="o">.</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Path</span><span class="p">],</span> <span class="n">include_optimizer</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
    <span class="sd">"""</span>
<span class="sd">    Saves the model to disk.</span>

<span class="sd">    It creates a directory that includes:</span>

<span class="sd">    - The `Model` object instance serialized with `pickle` as</span>
<span class="sd">        as `{path}/model.pkl`, this allows you to re-instantiate </span>
<span class="sd">        the model later.</span>
<span class="sd">    - The model parameters + states serialized into HDF5 as `{path}/parameters.h5`.</span>
<span class="sd">    - The state of the optimizer serialized with `pickle` as</span>
<span class="sd">        as `{path}/optimizer_state.pkl`, allowing to resume training</span>
<span class="sd">        exactly where you left off. We hope to use HDF5 in the future</span>
<span class="sd">        but `optix` state is incompatible with `deepdish`.</span>

<span class="sd">    This allows you to save the entirety of the state of a model</span>
<span class="sd">    in a directory structure which can be fully restored via </span>
<span class="sd">    `Model.load` if the model is already instiated or `elegy.model.load`</span>
<span class="sd">    to load the model instance from its pickled version.</span>

<span class="sd">    ```python</span>
<span class="sd">    import elegy</span>

<span class="sd">    model.save('my_model')  # creates folder at 'my_model'</span>
<span class="sd">    del model  # deletes the existing model</span>

<span class="sd">    # returns a model identical to the previous one</span>
<span class="sd">    model = elegy.model.load('my_model')</span>
<span class="sd">    ```</span>
<span class="sd">    Arguments:</span>
<span class="sd">        path: path where model structure will be saved.</span>
<span class="sd">        include_optimizer: If True, save optimizer's state together.</span>
<span class="sd">    """</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
        <span class="n">path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>

    <span class="n">path</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="n">parents</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="n">state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">full_state</span>

    <span class="n">original_state</span> <span class="o">=</span> <span class="n">copy</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>

    <span class="n">state</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">"metrics_state"</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
    <span class="n">state</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">"initial_metrics_state"</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

    <span class="n">optimizer_state</span> <span class="o">=</span> <span class="n">state</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">"optimizer_state"</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

    <span class="n">deepdish</span><span class="o">.</span><span class="n">io</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">path</span> <span class="o">/</span> <span class="s2">"parameters.h5"</span><span class="p">,</span> <span class="n">state</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">include_optimizer</span> <span class="ow">and</span> <span class="n">optimizer_state</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">path</span> <span class="o">/</span> <span class="s2">"optimizer_state.pkl"</span><span class="p">,</span> <span class="s2">"wb"</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">optimizer_state</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>

    <span class="c1"># getting pickle errors</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_clear_state</span><span class="p">()</span>

    <span class="k">try</span><span class="p">:</span>
        <span class="n">path</span> <span class="o">=</span> <span class="n">path</span> <span class="o">/</span> <span class="s2">"model.pkl"</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="s2">"wb"</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="n">cloudpickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>
    <span class="k">except</span> <span class="ne">BaseException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Error occurred saving the model object at </span><span class="si">{</span><span class="n">path</span><span class="si">}</span><span class="se">\n</span><span class="s2">Continuing...."</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">full_state</span> <span class="o">=</span> <span class="n">original_state</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h2 class="doc doc-heading" id="elegy.model.Model.summary">
<code class="highlight language-python">
summary<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">depth</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">tablefmt</span><span class="o">=</span><span class="s1">'fancy_grid'</span><span class="p">,</span> <span class="o">**</span><span class="n">tablulate_kwargs</span><span class="p">)</span> </code>
</h2>
<div class="doc doc-contents">
<p>Prints a summary of the network.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>x</code></td>
<td><code></code></td>
<td>
<p>A sample of inputs to the network.</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>depth</code></td>
<td><code>int</code></td>
<td>
<p>The level number of nested level which will be showed.
Information about summaries from modules deeper than <code>depth</code> 
will be aggregated together.</p>
</td>
<td><code>3</code></td>
</tr>
<tr>
<td><code>tablefmt</code></td>
<td><code>str</code></td>
<td>
<p>A string represeting the style of the table generated by
<code>tabulate</code>. See
<a href="https://github.com/astanin/python-tabulate">python-tabulate</a>
for more options.</p>
</td>
<td><code>'fancy_grid'</code></td>
</tr>
<tr>
<td><code>tablulate_kwargs</code></td>
<td><code></code></td>
<td>
<p>Additional keyword arguments passed to <code>tabulate</code>.
See <a href="https://github.com/astanin/python-tabulate">python-tabulate</a>
for more options.</p>
</td>
<td><code>{}</code></td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>elegy/model.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>1321
1322
1323
1324
1325
1326
1327
1328
1329
1330
1331
1332
1333
1334
1335
1336
1337
1338
1339
1340
1341
1342
1343
1344
1345
1346
1347
1348
1349
1350
1351
1352
1353
1354
1355
1356
1357
1358
1359
1360
1361
1362
1363
1364
1365
1366
1367
1368
1369
1370
1371
1372
1373
1374
1375
1376
1377
1378
1379
1380
1381
1382
1383
1384
1385
1386
1387
1388
1389
1390
1391
1392
1393
1394
1395
1396
1397
1398
1399
1400
1401
1402
1403
1404
1405
1406
1407
1408
1409
1410
1411
1412
1413
1414
1415
1416
1417
1418
1419
1420
1421
1422
1423
1424
1425
1426
1427
1428
1429
1430
1431
1432
1433
1434
1435
1436
1437
1438
1439
1440
1441
1442
1443
1444
1445
1446
1447
1448
1449
1450
1451
1452
1453
1454
1455
1456
1457
1458
1459
1460
1461
1462
1463
1464
1465
1466
1467
1468
1469
1470
1471
1472
1473
1474
1475
1476
1477
1478
1479
1480</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">summary</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">depth</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span> <span class="n">tablefmt</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">"fancy_grid"</span><span class="p">,</span> <span class="o">**</span><span class="n">tablulate_kwargs</span>
<span class="p">):</span>
    <span class="sd">"""</span>
<span class="sd">    Prints a summary of the network.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        x: A sample of inputs to the network.</span>
<span class="sd">        depth: The level number of nested level which will be showed.</span>
<span class="sd">            Information about summaries from modules deeper than `depth` </span>
<span class="sd">            will be aggregated together.</span>
<span class="sd">        tablefmt: A string represeting the style of the table generated by</span>
<span class="sd">            `tabulate`. See</span>
<span class="sd">            [python-tabulate](https://github.com/astanin/python-tabulate)</span>
<span class="sd">            for more options.</span>
<span class="sd">        tablulate_kwargs: Additional keyword arguments passed to `tabulate`.</span>
<span class="sd">            See [python-tabulate](https://github.com/astanin/python-tabulate)</span>
<span class="sd">            for more options.</span>
<span class="sd">    """</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_maybe_initialize</span><span class="p">(</span>
        <span class="n">mode</span><span class="o">=</span><span class="n">Mode</span><span class="o">.</span><span class="n">predict</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">class_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">transformed_state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_predict</span><span class="p">(</span>
        <span class="n">is_training</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">get_summaries</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span>
        <span class="n">params</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">,</span>
        <span class="n">state</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="p">,</span>
        <span class="n">net_rng</span><span class="o">=</span><span class="nb">next</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_rngs</span><span class="p">),</span>
    <span class="p">)</span>

    <span class="k">def</span> <span class="nf">format_output</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="n">file</span> <span class="o">=</span> <span class="n">StringIO</span><span class="p">()</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">tree_map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="se">{{</span><span class="s2">pad</span><span class="se">}}</span><span class="s2">  </span><span class="si">{</span><span class="n">x</span><span class="o">.</span><span class="n">dtype</span><span class="si">}</span><span class="s2">"</span><span class="p">,</span> <span class="n">outputs</span><span class="p">)</span>
        <span class="n">yaml</span><span class="o">.</span><span class="n">safe_dump</span><span class="p">(</span>
            <span class="n">outputs</span><span class="p">,</span> <span class="n">file</span><span class="p">,</span> <span class="n">default_flow_style</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">indent</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">explicit_end</span><span class="o">=</span><span class="kc">False</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">file</span><span class="o">.</span><span class="n">getvalue</span><span class="p">()</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">"</span><span class="se">\n</span><span class="s2">..."</span><span class="p">,</span> <span class="s2">""</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">format_size</span><span class="p">(</span><span class="n">size</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">(</span>
            <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">size</span> <span class="o">/</span> <span class="mf">1e9</span> <span class="si">:</span><span class="s2">,.1f</span><span class="si">}</span><span class="s2"> GB"</span>
            <span class="k">if</span> <span class="n">size</span> <span class="o">&gt;</span> <span class="mf">1e9</span>
            <span class="k">else</span> <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">size</span> <span class="o">/</span> <span class="mf">1e6</span> <span class="si">:</span><span class="s2">,.1f</span><span class="si">}</span><span class="s2"> MB"</span>
            <span class="k">if</span> <span class="n">size</span> <span class="o">&gt;</span> <span class="mf">1e6</span>
            <span class="k">else</span> <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">size</span> <span class="o">/</span> <span class="mf">1e3</span> <span class="si">:</span><span class="s2">,.1f</span><span class="si">}</span><span class="s2"> KB"</span>
            <span class="k">if</span> <span class="n">size</span> <span class="o">&gt;</span> <span class="mf">1e3</span>
            <span class="k">else</span> <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">size</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2"> B"</span>
        <span class="p">)</span>

    <span class="n">summaries</span> <span class="o">=</span> <span class="p">(</span>
        <span class="p">(</span><span class="nb">tuple</span><span class="p">(</span><span class="n">name</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">"/"</span><span class="p">)),</span> <span class="n">cls_name</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">cls_name</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">transformed_state</span><span class="o">.</span><span class="n">summaries</span>
    <span class="p">)</span>

    <span class="n">summaries</span> <span class="o">=</span> <span class="n">toolz</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">][:</span><span class="n">depth</span><span class="p">],</span> <span class="n">summaries</span><span class="p">)</span>
    <span class="n">params</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">split_and_merge</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">)</span>
    <span class="n">state</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">split_and_merge</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="p">)</span>

    <span class="n">table</span><span class="p">:</span> <span class="n">tp</span><span class="o">.</span><span class="n">List</span> <span class="o">=</span> <span class="p">[[</span><span class="s2">"Inputs"</span><span class="p">,</span> <span class="n">format_output</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="s2">"0"</span><span class="p">,</span> <span class="s2">"0"</span><span class="p">]]</span>

    <span class="k">for</span> <span class="n">keys</span><span class="p">,</span> <span class="n">group</span> <span class="ow">in</span> <span class="n">summaries</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">group</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="mi">2</span><span class="p">]</span>
        <span class="n">class_name</span> <span class="o">=</span> <span class="n">group</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span>

        <span class="n">sub_params</span> <span class="o">=</span> <span class="n">params</span>
        <span class="n">sub_states</span> <span class="o">=</span> <span class="n">state</span>

        <span class="k">try</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">keys</span><span class="p">:</span>
                <span class="n">sub_params</span> <span class="o">=</span> <span class="n">sub_params</span><span class="p">[</span><span class="n">k</span><span class="p">]</span>
        <span class="k">except</span> <span class="ne">KeyError</span><span class="p">:</span>
            <span class="n">sub_params</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="k">try</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">keys</span><span class="p">:</span>
                <span class="n">sub_states</span> <span class="o">=</span> <span class="n">sub_states</span><span class="p">[</span><span class="n">k</span><span class="p">]</span>
        <span class="k">except</span> <span class="ne">KeyError</span><span class="p">:</span>
            <span class="n">sub_states</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="n">params_count</span> <span class="o">=</span> <span class="n">hk</span><span class="o">.</span><span class="n">data_structures</span><span class="o">.</span><span class="n">tree_size</span><span class="p">(</span><span class="n">sub_params</span><span class="p">)</span>
        <span class="n">params_size</span> <span class="o">=</span> <span class="n">format_size</span><span class="p">(</span><span class="n">hk</span><span class="o">.</span><span class="n">data_structures</span><span class="o">.</span><span class="n">tree_bytes</span><span class="p">(</span><span class="n">sub_params</span><span class="p">))</span>
        <span class="n">states_count</span> <span class="o">=</span> <span class="n">hk</span><span class="o">.</span><span class="n">data_structures</span><span class="o">.</span><span class="n">tree_size</span><span class="p">(</span><span class="n">sub_states</span><span class="p">)</span>
        <span class="n">states_size</span> <span class="o">=</span> <span class="n">format_size</span><span class="p">(</span><span class="n">hk</span><span class="o">.</span><span class="n">data_structures</span><span class="o">.</span><span class="n">tree_bytes</span><span class="p">(</span><span class="n">sub_states</span><span class="p">))</span>

        <span class="n">table</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
            <span class="p">[</span>
                <span class="s2">"/"</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">keys</span><span class="p">)</span> <span class="o">+</span> <span class="sa">f</span><span class="s2">"</span><span class="se">{{</span><span class="s2">pad</span><span class="se">}}</span><span class="s2">  (</span><span class="si">{</span><span class="n">class_name</span><span class="si">}</span><span class="s2">)"</span><span class="p">,</span>
                <span class="n">format_output</span><span class="p">(</span><span class="n">output</span><span class="p">),</span>
                <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">params_count</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="se">{{</span><span class="s2">pad</span><span class="se">}}</span><span class="s2">    </span><span class="si">{</span><span class="n">params_size</span><span class="si">}</span><span class="s2">"</span>
                <span class="k">if</span> <span class="n">params_count</span> <span class="o">&gt;</span> <span class="mi">0</span>
                <span class="k">else</span> <span class="s2">"0"</span><span class="p">,</span>
                <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">states_count</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="se">{{</span><span class="s2">pad</span><span class="se">}}</span><span class="s2">    </span><span class="si">{</span><span class="n">states_size</span><span class="si">}</span><span class="s2">"</span>
                <span class="k">if</span> <span class="n">states_count</span> <span class="o">&gt;</span> <span class="mi">0</span>
                <span class="k">else</span> <span class="s2">"0"</span><span class="p">,</span>
            <span class="p">]</span>
        <span class="p">)</span>

    <span class="c1"># add papdding</span>
    <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">4</span><span class="p">):</span>
        <span class="n">max_length</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span>
            <span class="nb">len</span><span class="p">(</span><span class="n">line</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">"</span><span class="si">{pad}</span><span class="s2">"</span><span class="p">)[</span><span class="mi">0</span><span class="p">])</span>
            <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">table</span>
            <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">row</span><span class="p">[</span><span class="n">col</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">"</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>
        <span class="p">)</span>

        <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">table</span><span class="p">:</span>
            <span class="n">row</span><span class="p">[</span><span class="n">col</span><span class="p">]</span> <span class="o">=</span> <span class="s2">"</span><span class="se">\n</span><span class="s2">"</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
                <span class="n">line</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                    <span class="n">pad</span><span class="o">=</span><span class="s2">" "</span> <span class="o">*</span> <span class="p">(</span><span class="n">max_length</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">line</span><span class="o">.</span><span class="n">rstrip</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">"</span><span class="si">{pad}</span><span class="s2">"</span><span class="p">)[</span><span class="mi">0</span><span class="p">]))</span>
                <span class="p">)</span>
                <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">row</span><span class="p">[</span><span class="n">col</span><span class="p">]</span><span class="o">.</span><span class="n">rstrip</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">"</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>
            <span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span>
        <span class="s2">"</span><span class="se">\n</span><span class="s2">"</span>
        <span class="o">+</span> <span class="n">tabulate</span><span class="p">(</span>
            <span class="n">table</span><span class="p">,</span>
            <span class="n">headers</span><span class="o">=</span><span class="p">[</span>
                <span class="s2">"Layer"</span><span class="p">,</span>
                <span class="s2">"Outputs Shape"</span><span class="p">,</span>
                <span class="s2">"Trainable</span><span class="se">\n</span><span class="s2">Parameters"</span><span class="p">,</span>
                <span class="s2">"Non-trainable</span><span class="se">\n</span><span class="s2">Parameters"</span><span class="p">,</span>
            <span class="p">],</span>
            <span class="n">tablefmt</span><span class="o">=</span><span class="n">tablefmt</span><span class="p">,</span>
            <span class="o">**</span><span class="n">tablulate_kwargs</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="p">)</span>

    <span class="n">params_count</span> <span class="o">=</span> <span class="n">hk</span><span class="o">.</span><span class="n">data_structures</span><span class="o">.</span><span class="n">tree_size</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">)</span>
    <span class="n">params_size</span> <span class="o">=</span> <span class="n">hk</span><span class="o">.</span><span class="n">data_structures</span><span class="o">.</span><span class="n">tree_bytes</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">)</span>
    <span class="n">states_count</span> <span class="o">=</span> <span class="n">hk</span><span class="o">.</span><span class="n">data_structures</span><span class="o">.</span><span class="n">tree_size</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="p">)</span>
    <span class="n">states_size</span> <span class="o">=</span> <span class="n">hk</span><span class="o">.</span><span class="n">data_structures</span><span class="o">.</span><span class="n">tree_bytes</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="p">)</span>
    <span class="n">total_count</span> <span class="o">=</span> <span class="n">params_count</span> <span class="o">+</span> <span class="n">states_count</span>
    <span class="n">total_size</span> <span class="o">=</span> <span class="n">params_size</span> <span class="o">+</span> <span class="n">states_size</span>

    <span class="nb">print</span><span class="p">(</span>
        <span class="n">tabulate</span><span class="p">(</span>
            <span class="p">[</span>
                <span class="p">[</span>
                    <span class="sa">f</span><span class="s2">"Total Parameters:"</span><span class="p">,</span>
                    <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">total_count</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2">"</span><span class="p">,</span>
                    <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">format_size</span><span class="p">(</span><span class="n">total_size</span><span class="p">)</span><span class="si">}</span><span class="s2">"</span> <span class="k">if</span> <span class="n">total_count</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="s2">""</span><span class="p">,</span>
                <span class="p">],</span>
                <span class="p">[</span>
                    <span class="sa">f</span><span class="s2">"Trainable Parameters:"</span><span class="p">,</span>
                    <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">params_count</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2">"</span><span class="p">,</span>
                    <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">format_size</span><span class="p">(</span><span class="n">params_size</span><span class="p">)</span><span class="si">}</span><span class="s2">"</span> <span class="k">if</span> <span class="n">params_count</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="s2">""</span><span class="p">,</span>
                <span class="p">],</span>
                <span class="p">[</span>
                    <span class="sa">f</span><span class="s2">"Non-trainable Parameters:"</span><span class="p">,</span>
                    <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">states_count</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2">"</span><span class="p">,</span>
                    <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">format_size</span><span class="p">(</span><span class="n">states_size</span><span class="p">)</span><span class="si">}</span><span class="s2">"</span> <span class="k">if</span> <span class="n">states_count</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="s2">""</span><span class="p">,</span>
                <span class="p">],</span>
            <span class="p">],</span>
            <span class="n">tablefmt</span><span class="o">=</span><span class="s2">"plain"</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="o">+</span> <span class="s2">"</span><span class="se">\n</span><span class="s2">"</span>
    <span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h2 class="doc doc-heading" id="elegy.model.Model.test_on_batch">
<code class="highlight language-python">
test_on_batch<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">class_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> </code>
</h2>
<div class="doc doc-contents">
<p>Test the model on a single batch of samples.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>x</code></td>
<td><code>Union[jax.numpy.lax_numpy.ndarray, Mapping[str, Any], Tuple]</code></td>
<td>
<p>Input data. It could be: </p>
<ul>
<li>A Numpy array (or array-like), or a list
    of arrays (in case the model has multiple inputs). </li>
<li>A dict mapping input names to the corresponding arrays, if
    the model has named inputs.</li>
</ul>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>y</code></td>
<td><code>Optional[Union[jax.numpy.lax_numpy.ndarray, Mapping[str, Any], Tuple]]</code></td>
<td>
<p>Target data. Like the input data <code>x</code>, it could be either Numpy
array(s) or Jax array(s).</p>
</td>
<td><code>None</code></td>
</tr>
<tr>
<td><code>sample_weight</code></td>
<td><code>Optional[jax.numpy.lax_numpy.ndarray]</code></td>
<td>
<p>Optional array of the same length as x, containing
weights to apply to the model's loss for each sample. In the case of
temporal data, you can pass a 2D array with shape (samples,
sequence_length), to apply a different weight to every timestep of
every sample.</p>
</td>
<td><code>None</code></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>Dict[str, jax.numpy.lax_numpy.ndarray]</code></td>
<td>
<p>A <code>logs</code> dictionary of containing the main <code>loss</code> as well as all
other losses and metrics. </p>
</td>
</tr>
</tbody>
</table>
<p><strong>Exceptions:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>ValueError</code></td>
<td>
<p>In case of invalid user-provided arguments.</p>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>elegy/model.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span> 955
 956
 957
 958
 959
 960
 961
 962
 963
 964
 965
 966
 967
 968
 969
 970
 971
 972
 973
 974
 975
 976
 977
 978
 979
 980
 981
 982
 983
 984
 985
 986
 987
 988
 989
 990
 991
 992
 993
 994
 995
 996
 997
 998
 999
1000
1001
1002
1003
1004
1005
1006</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">test_on_batch</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">tp</span><span class="o">.</span><span class="n">Union</span><span class="p">[</span><span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">tp</span><span class="o">.</span><span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">tp</span><span class="o">.</span><span class="n">Any</span><span class="p">],</span> <span class="n">tp</span><span class="o">.</span><span class="n">Tuple</span><span class="p">],</span>
    <span class="n">y</span><span class="p">:</span> <span class="n">tp</span><span class="o">.</span><span class="n">Union</span><span class="p">[</span><span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">tp</span><span class="o">.</span><span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">tp</span><span class="o">.</span><span class="n">Any</span><span class="p">],</span> <span class="n">tp</span><span class="o">.</span><span class="n">Tuple</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">sample_weight</span><span class="p">:</span> <span class="n">tp</span><span class="o">.</span><span class="n">Optional</span><span class="p">[</span><span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">class_weight</span><span class="p">:</span> <span class="n">tp</span><span class="o">.</span><span class="n">Optional</span><span class="p">[</span><span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">tp</span><span class="o">.</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]:</span>
    <span class="sd">"""</span>
<span class="sd">    Test the model on a single batch of samples.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        x: Input data. It could be: </span>

<span class="sd">            - A Numpy array (or array-like), or a list</span>
<span class="sd">                of arrays (in case the model has multiple inputs). </span>
<span class="sd">            - A dict mapping input names to the corresponding arrays, if</span>
<span class="sd">                the model has named inputs.</span>
<span class="sd">        y: Target data. Like the input data `x`, it could be either Numpy</span>
<span class="sd">            array(s) or Jax array(s).</span>
<span class="sd">        sample_weight: Optional array of the same length as x, containing</span>
<span class="sd">            weights to apply to the model's loss for each sample. In the case of</span>
<span class="sd">            temporal data, you can pass a 2D array with shape (samples,</span>
<span class="sd">            sequence_length), to apply a different weight to every timestep of</span>
<span class="sd">            every sample.</span>

<span class="sd">    Returns:</span>
<span class="sd">        A `logs` dictionary of containing the main `loss` as well as all</span>
<span class="sd">        other losses and metrics. </span>
<span class="sd">    Raises:</span>
<span class="sd">        ValueError: In case of invalid user-provided arguments.</span>
<span class="sd">    """</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_maybe_initialize</span><span class="p">(</span>
        <span class="n">mode</span><span class="o">=</span><span class="n">Mode</span><span class="o">.</span><span class="n">test</span><span class="p">,</span>
        <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span>
        <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span>
        <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">,</span>
        <span class="n">class_weight</span><span class="o">=</span><span class="n">class_weight</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="p">(</span><span class="n">logs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">metrics_state</span><span class="p">,)</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_test</span><span class="p">(</span>
        <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span>
        <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span>
        <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">,</span>
        <span class="n">class_weight</span><span class="o">=</span><span class="n">class_weight</span><span class="p">,</span>
        <span class="n">params</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">,</span>
        <span class="n">state</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="p">,</span>
        <span class="n">metrics_state</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">metrics_state</span><span class="p">,</span>
        <span class="n">net_rng</span><span class="o">=</span><span class="nb">next</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_rngs</span><span class="p">),</span>
        <span class="n">metrics_rng</span><span class="o">=</span><span class="nb">next</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_rngs</span><span class="p">),</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="p">{</span><span class="n">key</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">value</span><span class="p">)</span> <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">logs</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h2 class="doc doc-heading" id="elegy.model.Model.train_on_batch">
<code class="highlight language-python">
train_on_batch<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">class_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> </code>
</h2>
<div class="doc doc-contents">
<p>Runs a single gradient update on a single batch of data.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>x</code></td>
<td><code>Union[numpy.ndarray, Mapping[str, Any], Tuple]</code></td>
<td>
<p>Input data. It could be:</p>
<ul>
<li>A Numpy array (or array-like), or a iterable of arrays
    (in case the model has multiple inputs).</li>
<li>A dict mapping input names to the corresponding arrays,
    if the model has named inputs.</li>
</ul>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>y</code></td>
<td><code>Optional[Union[numpy.ndarray, Mapping[str, Any], Tuple]]</code></td>
<td>
<p>Target data. Like the input data <code>x</code>, it could be either Numpy
array(s) or Jax array(s). It should be consistent with <code>x</code>
(you cannot have Numpy inputs and array targets, or inversely).</p>
</td>
<td><code>None</code></td>
</tr>
<tr>
<td><code>sample_weight</code></td>
<td><code>Optional[numpy.ndarray]</code></td>
<td>
<p>Optional array of the same length as x, containing
weights to apply to the model's loss for each sample. In the case of
temporal data, you can pass a 2D array with shape (samples,
sequence_length), to apply a different weight to every timestep of
every sample.</p>
</td>
<td><code>None</code></td>
</tr>
<tr>
<td><code>class_weight</code></td>
<td><code>Optional[numpy.ndarray]</code></td>
<td>
<p>Optional dictionary mapping class indices (integers) to a
weight (float) to apply to the model's loss for the samples from this
class during training. This can be useful to tell the model to "pay
more attention" to samples from an under-represented class.</p>
</td>
<td><code>None</code></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>Dict[str, numpy.ndarray]</code></td>
<td>
<p>A <code>logs</code> dictionary of containing the main <code>loss</code> as well as all
other losses and metrics. </p>
</td>
</tr>
</tbody>
</table>
<p><strong>Exceptions:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>ValueError</code></td>
<td>
<p>In case of invalid user-provided arguments.</p>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>elegy/model.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">train_on_batch</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">tp</span><span class="o">.</span><span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">tp</span><span class="o">.</span><span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">tp</span><span class="o">.</span><span class="n">Any</span><span class="p">],</span> <span class="n">tp</span><span class="o">.</span><span class="n">Tuple</span><span class="p">],</span>
    <span class="n">y</span><span class="p">:</span> <span class="n">tp</span><span class="o">.</span><span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">tp</span><span class="o">.</span><span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">tp</span><span class="o">.</span><span class="n">Any</span><span class="p">],</span> <span class="n">tp</span><span class="o">.</span><span class="n">Tuple</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">sample_weight</span><span class="p">:</span> <span class="n">tp</span><span class="o">.</span><span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">class_weight</span><span class="p">:</span> <span class="n">tp</span><span class="o">.</span><span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">tp</span><span class="o">.</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]:</span>
    <span class="sd">"""</span>
<span class="sd">    Runs a single gradient update on a single batch of data.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        x: Input data. It could be:</span>

<span class="sd">            - A Numpy array (or array-like), or a iterable of arrays</span>
<span class="sd">                (in case the model has multiple inputs).</span>
<span class="sd">            - A dict mapping input names to the corresponding arrays,</span>
<span class="sd">                if the model has named inputs.</span>
<span class="sd">        y: Target data. Like the input data `x`, it could be either Numpy</span>
<span class="sd">            array(s) or Jax array(s). It should be consistent with `x`</span>
<span class="sd">            (you cannot have Numpy inputs and array targets, or inversely).</span>
<span class="sd">        sample_weight: Optional array of the same length as x, containing</span>
<span class="sd">            weights to apply to the model's loss for each sample. In the case of</span>
<span class="sd">            temporal data, you can pass a 2D array with shape (samples,</span>
<span class="sd">            sequence_length), to apply a different weight to every timestep of</span>
<span class="sd">            every sample.</span>
<span class="sd">        class_weight: Optional dictionary mapping class indices (integers) to a</span>
<span class="sd">            weight (float) to apply to the model's loss for the samples from this</span>
<span class="sd">            class during training. This can be useful to tell the model to "pay</span>
<span class="sd">            more attention" to samples from an under-represented class.</span>

<span class="sd">    Returns:</span>
<span class="sd">        A `logs` dictionary of containing the main `loss` as well as all</span>
<span class="sd">        other losses and metrics. </span>

<span class="sd">    Raises:</span>
<span class="sd">        ValueError: In case of invalid user-provided arguments.</span>
<span class="sd">    """</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_maybe_initialize</span><span class="p">(</span>
        <span class="n">mode</span><span class="o">=</span><span class="n">Mode</span><span class="o">.</span><span class="n">train</span><span class="p">,</span>
        <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span>
        <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span>
        <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">,</span>
        <span class="n">class_weight</span><span class="o">=</span><span class="n">class_weight</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="p">(</span>
        <span class="n">logs</span><span class="p">,</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">,</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="p">,</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer_state</span><span class="p">,</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">metrics_state</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_update</span><span class="p">(</span>
        <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span>
        <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span>
        <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">,</span>
        <span class="n">class_weight</span><span class="o">=</span><span class="n">class_weight</span><span class="p">,</span>
        <span class="n">params</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">,</span>
        <span class="n">state</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="p">,</span>
        <span class="n">optimizer_state</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">optimizer_state</span><span class="p">,</span>
        <span class="n">metrics_state</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">metrics_state</span><span class="p">,</span>
        <span class="n">net_rng</span><span class="o">=</span><span class="nb">next</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_rngs</span><span class="p">),</span>
        <span class="n">metrics_rng</span><span class="o">=</span><span class="nb">next</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_rngs</span><span class="p">),</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="p">{</span><span class="n">key</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">value</span><span class="p">)</span> <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">logs</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
</article>
</div>
</div>
</main>
<footer class="md-footer">
<div class="md-footer-nav">
<nav aria-label="Footer" class="md-footer-nav__inner md-grid">
<a class="md-footer-nav__link md-footer-nav__link--prev" href="../../module/Defered/" rel="prev" title="Defered">
<div class="md-footer-nav__button md-icon">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"></path></svg>
</div>
<div class="md-footer-nav__title">
<div class="md-ellipsis">
<span class="md-footer-nav__direction">
                  Previous
                </span>
                Defered
              </div>
</div>
</a>
<a class="md-footer-nav__link md-footer-nav__link--next" href="../load/" rel="next" title="load">
<div class="md-footer-nav__title">
<div class="md-ellipsis">
<span class="md-footer-nav__direction">
                  Next
                </span>
                load
              </div>
</div>
<div class="md-footer-nav__button md-icon">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4z"></path></svg>
</div>
</a>
</nav>
</div>
<div class="md-footer-meta md-typeset">
<div class="md-footer-meta__inner md-grid">
<div class="md-footer-copyright">
        
        Made with
        <a href="https://squidfunk.github.io/mkdocs-material/" rel="noopener" target="_blank">
          Material for MkDocs
        </a>
</div>
<div class="md-footer-social">
<a class="md-footer-social__link" href="https://github.com/cgarciae" rel="noopener" target="_blank" title="github.com">
<svg viewbox="0 0 16 16" xmlns="http://www.w3.org/2000/svg"><path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z" fill-rule="evenodd"></path></svg>
</a>
<a class="md-footer-social__link" href="https://github.com/charlielito" rel="noopener" target="_blank" title="github.com">
<svg viewbox="0 0 16 16" xmlns="http://www.w3.org/2000/svg"><path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z" fill-rule="evenodd"></path></svg>
</a>
<a class="md-footer-social__link" href="https://twitter.com/cgarciae88" rel="noopener" target="_blank" title="twitter.com">
<svg viewbox="0 0 512 512" xmlns="http://www.w3.org/2000/svg"><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"></path></svg>
</a>
<a class="md-footer-social__link" href="https://www.linkedin.com/in/cgarciae" rel="noopener" target="_blank" title="www.linkedin.com">
<svg viewbox="0 0 448 512" xmlns="http://www.w3.org/2000/svg"><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"></path></svg>
</a>
<a class="md-footer-social__link" href="https://www.linkedin.com/in/calvarez92" rel="noopener" target="_blank" title="www.linkedin.com">
<svg viewbox="0 0 448 512" xmlns="http://www.w3.org/2000/svg"><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"></path></svg>
</a>
</div>
</div>
</div>
</footer>
</div>
<script src="../../../assets/javascripts/vendor.92ffa368.min.js"></script>
<script src="../../../assets/javascripts/bundle.5123e3d4.min.js"></script><script id="__lang" type="application/json">{"clipboard.copy": "Copy to clipboard", "clipboard.copied": "Copied to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.result.placeholder": "Type to start searching", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents"}</script>
<script>
        app = initialize({
          base: "../../..",
          features: [],
          search: Object.assign({
            worker: "../../../assets/javascripts/worker/search.a68abb33.min.js"
          }, typeof search !== "undefined" && search)
        })
      </script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML"></script>
</body>
</html>